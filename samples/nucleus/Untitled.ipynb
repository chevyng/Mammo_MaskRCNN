{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chevy\\Anaconda3\\envs\\nnets\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  checkpoints/nuclei20180302T0150/mask_rcnn_nuclei_0098.h5\n",
      "\n",
      "Starting at epoch 99. LR=1e-06\n",
      "\n",
      "Checkpoint Path: checkpoints\\nuclei20180302T0150\\mask_rcnn_nuclei_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chevy\\Anaconda3\\envs\\nnets\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:616: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n",
      "C:\\Users\\Chevy\\Anaconda3\\envs\\nnets\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 100/123\n",
      "300/300 [==============================] - 783s 3s/step - loss: 0.2960 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.0402 - mrcnn_class_loss: 0.0313 - mrcnn_bbox_loss: 0.0439 - mrcnn_mask_loss: 0.1765 - val_loss: 0.3672 - val_rpn_class_loss: 0.0020 - val_rpn_bbox_loss: 0.0876 - val_mrcnn_class_loss: 0.0144 - val_mrcnn_bbox_loss: 0.0894 - val_mrcnn_mask_loss: 0.1738\n",
      "Epoch 101/123\n",
      "300/300 [==============================] - 736s 2s/step - loss: 0.2942 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.0407 - mrcnn_class_loss: 0.0313 - mrcnn_bbox_loss: 0.0436 - mrcnn_mask_loss: 0.1747 - val_loss: 0.3663 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0869 - val_mrcnn_class_loss: 0.0131 - val_mrcnn_bbox_loss: 0.0900 - val_mrcnn_mask_loss: 0.1745\n",
      "Epoch 102/123\n",
      "300/300 [==============================] - 738s 2s/step - loss: 0.2901 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.0391 - mrcnn_class_loss: 0.0315 - mrcnn_bbox_loss: 0.0428 - mrcnn_mask_loss: 0.1732 - val_loss: 0.3649 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0861 - val_mrcnn_class_loss: 0.0133 - val_mrcnn_bbox_loss: 0.0907 - val_mrcnn_mask_loss: 0.1729\n",
      "Epoch 103/123\n",
      "300/300 [==============================] - 735s 2s/step - loss: 0.2947 - rpn_class_loss: 0.0041 - rpn_bbox_loss: 0.0400 - mrcnn_class_loss: 0.0307 - mrcnn_bbox_loss: 0.0433 - mrcnn_mask_loss: 0.1766 - val_loss: 0.3679 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0868 - val_mrcnn_class_loss: 0.0161 - val_mrcnn_bbox_loss: 0.0903 - val_mrcnn_mask_loss: 0.1727\n",
      "Epoch 104/123\n",
      "300/300 [==============================] - 734s 2s/step - loss: 0.2910 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.0385 - mrcnn_class_loss: 0.0306 - mrcnn_bbox_loss: 0.0429 - mrcnn_mask_loss: 0.1753 - val_loss: 0.3662 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0872 - val_mrcnn_class_loss: 0.0151 - val_mrcnn_bbox_loss: 0.0885 - val_mrcnn_mask_loss: 0.1734\n",
      "Epoch 105/123\n",
      "300/300 [==============================] - 741s 2s/step - loss: 0.2905 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.0383 - mrcnn_class_loss: 0.0312 - mrcnn_bbox_loss: 0.0425 - mrcnn_mask_loss: 0.1747 - val_loss: 0.3705 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0871 - val_mrcnn_class_loss: 0.0189 - val_mrcnn_bbox_loss: 0.0890 - val_mrcnn_mask_loss: 0.1735\n",
      "Epoch 106/123\n",
      "300/300 [==============================] - 736s 2s/step - loss: 0.2905 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.0395 - mrcnn_class_loss: 0.0314 - mrcnn_bbox_loss: 0.0420 - mrcnn_mask_loss: 0.1739 - val_loss: 0.3725 - val_rpn_class_loss: 0.0020 - val_rpn_bbox_loss: 0.0876 - val_mrcnn_class_loss: 0.0208 - val_mrcnn_bbox_loss: 0.0888 - val_mrcnn_mask_loss: 0.1734\n",
      "Epoch 107/123\n",
      "300/300 [==============================] - 742s 2s/step - loss: 0.2856 - rpn_class_loss: 0.0034 - rpn_bbox_loss: 0.0377 - mrcnn_class_loss: 0.0310 - mrcnn_bbox_loss: 0.0414 - mrcnn_mask_loss: 0.1720 - val_loss: 0.3682 - val_rpn_class_loss: 0.0020 - val_rpn_bbox_loss: 0.0865 - val_mrcnn_class_loss: 0.0149 - val_mrcnn_bbox_loss: 0.0903 - val_mrcnn_mask_loss: 0.1745\n",
      "Epoch 108/123\n",
      "300/300 [==============================] - 731s 2s/step - loss: 0.2879 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.0379 - mrcnn_class_loss: 0.0309 - mrcnn_bbox_loss: 0.0420 - mrcnn_mask_loss: 0.1733 - val_loss: 0.3678 - val_rpn_class_loss: 0.0020 - val_rpn_bbox_loss: 0.0866 - val_mrcnn_class_loss: 0.0141 - val_mrcnn_bbox_loss: 0.0904 - val_mrcnn_mask_loss: 0.1747\n",
      "Epoch 109/123\n",
      "300/300 [==============================] - 730s 2s/step - loss: 0.2891 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.0381 - mrcnn_class_loss: 0.0310 - mrcnn_bbox_loss: 0.0422 - mrcnn_mask_loss: 0.1739 - val_loss: 0.3627 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0858 - val_mrcnn_class_loss: 0.0132 - val_mrcnn_bbox_loss: 0.0892 - val_mrcnn_mask_loss: 0.1725\n",
      "Epoch 110/123\n",
      "300/300 [==============================] - 738s 2s/step - loss: 0.2887 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.0376 - mrcnn_class_loss: 0.0310 - mrcnn_bbox_loss: 0.0419 - mrcnn_mask_loss: 0.1744 - val_loss: 0.3742 - val_rpn_class_loss: 0.0020 - val_rpn_bbox_loss: 0.0871 - val_mrcnn_class_loss: 0.0206 - val_mrcnn_bbox_loss: 0.0902 - val_mrcnn_mask_loss: 0.1743\n",
      "Epoch 111/123\n",
      "300/300 [==============================] - 750s 3s/step - loss: 0.2924 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.0393 - mrcnn_class_loss: 0.0324 - mrcnn_bbox_loss: 0.0424 - mrcnn_mask_loss: 0.1746 - val_loss: 0.3670 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0873 - val_mrcnn_class_loss: 0.0181 - val_mrcnn_bbox_loss: 0.0881 - val_mrcnn_mask_loss: 0.1716\n",
      "Epoch 112/123\n",
      "300/300 [==============================] - 735s 2s/step - loss: 0.2813 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.0367 - mrcnn_class_loss: 0.0296 - mrcnn_bbox_loss: 0.0403 - mrcnn_mask_loss: 0.1711 - val_loss: 0.3696 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0870 - val_mrcnn_class_loss: 0.0158 - val_mrcnn_bbox_loss: 0.0906 - val_mrcnn_mask_loss: 0.1742\n",
      "Epoch 113/123\n",
      "300/300 [==============================] - 738s 2s/step - loss: 0.2992 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.0403 - mrcnn_class_loss: 0.0323 - mrcnn_bbox_loss: 0.0437 - mrcnn_mask_loss: 0.1793 - val_loss: 0.3684 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0873 - val_mrcnn_class_loss: 0.0135 - val_mrcnn_bbox_loss: 0.0908 - val_mrcnn_mask_loss: 0.1748\n",
      "Epoch 114/123\n",
      "300/300 [==============================] - 738s 2s/step - loss: 0.2856 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.0378 - mrcnn_class_loss: 0.0309 - mrcnn_bbox_loss: 0.0408 - mrcnn_mask_loss: 0.1722 - val_loss: 0.3732 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0874 - val_mrcnn_class_loss: 0.0191 - val_mrcnn_bbox_loss: 0.0902 - val_mrcnn_mask_loss: 0.1746\n",
      "Epoch 115/123\n",
      "300/300 [==============================] - 742s 2s/step - loss: 0.2874 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.0379 - mrcnn_class_loss: 0.0311 - mrcnn_bbox_loss: 0.0413 - mrcnn_mask_loss: 0.1735 - val_loss: 0.3702 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0874 - val_mrcnn_class_loss: 0.0140 - val_mrcnn_bbox_loss: 0.0924 - val_mrcnn_mask_loss: 0.1745\n",
      "Epoch 116/123\n",
      "300/300 [==============================] - 765s 3s/step - loss: 0.2887 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.0396 - mrcnn_class_loss: 0.0301 - mrcnn_bbox_loss: 0.0416 - mrcnn_mask_loss: 0.1738 - val_loss: 0.3678 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0874 - val_mrcnn_class_loss: 0.0139 - val_mrcnn_bbox_loss: 0.0910 - val_mrcnn_mask_loss: 0.1736\n",
      "Epoch 117/123\n",
      "300/300 [==============================] - 745s 2s/step - loss: 0.2913 - rpn_class_loss: 0.0032 - rpn_bbox_loss: 0.0382 - mrcnn_class_loss: 0.0312 - mrcnn_bbox_loss: 0.0424 - mrcnn_mask_loss: 0.1762 - val_loss: 0.3733 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0876 - val_mrcnn_class_loss: 0.0201 - val_mrcnn_bbox_loss: 0.0903 - val_mrcnn_mask_loss: 0.1734\n",
      "Epoch 118/123\n",
      "300/300 [==============================] - 746s 2s/step - loss: 0.2881 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.0388 - mrcnn_class_loss: 0.0314 - mrcnn_bbox_loss: 0.0411 - mrcnn_mask_loss: 0.1731 - val_loss: 0.3733 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0878 - val_mrcnn_class_loss: 0.0156 - val_mrcnn_bbox_loss: 0.0925 - val_mrcnn_mask_loss: 0.1754\n",
      "Epoch 119/123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 739s 2s/step - loss: 0.2895 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.0386 - mrcnn_class_loss: 0.0314 - mrcnn_bbox_loss: 0.0416 - mrcnn_mask_loss: 0.1740 - val_loss: 0.3807 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0877 - val_mrcnn_class_loss: 0.0245 - val_mrcnn_bbox_loss: 0.0916 - val_mrcnn_mask_loss: 0.1750\n",
      "Epoch 120/123\n",
      "300/300 [==============================] - 730s 2s/step - loss: 0.2877 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.0384 - mrcnn_class_loss: 0.0294 - mrcnn_bbox_loss: 0.0418 - mrcnn_mask_loss: 0.1744 - val_loss: 0.3739 - val_rpn_class_loss: 0.0018 - val_rpn_bbox_loss: 0.0878 - val_mrcnn_class_loss: 0.0165 - val_mrcnn_bbox_loss: 0.0927 - val_mrcnn_mask_loss: 0.1750\n",
      "Epoch 121/123\n",
      "300/300 [==============================] - 740s 2s/step - loss: 0.2920 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.0392 - mrcnn_class_loss: 0.0311 - mrcnn_bbox_loss: 0.0426 - mrcnn_mask_loss: 0.1754 - val_loss: 0.3839 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0877 - val_mrcnn_class_loss: 0.0226 - val_mrcnn_bbox_loss: 0.0938 - val_mrcnn_mask_loss: 0.1779\n",
      "Epoch 122/123\n",
      "300/300 [==============================] - 747s 2s/step - loss: 0.2884 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.0386 - mrcnn_class_loss: 0.0309 - mrcnn_bbox_loss: 0.0409 - mrcnn_mask_loss: 0.1743 - val_loss: 0.3761 - val_rpn_class_loss: 0.0018 - val_rpn_bbox_loss: 0.0874 - val_mrcnn_class_loss: 0.0195 - val_mrcnn_bbox_loss: 0.0917 - val_mrcnn_mask_loss: 0.1756\n",
      "Epoch 123/123\n",
      "300/300 [==============================] - 739s 2s/step - loss: 0.2930 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.0394 - mrcnn_class_loss: 0.0313 - mrcnn_bbox_loss: 0.0424 - mrcnn_mask_loss: 0.1763 - val_loss: 0.3735 - val_rpn_class_loss: 0.0018 - val_rpn_bbox_loss: 0.0877 - val_mrcnn_class_loss: 0.0151 - val_mrcnn_bbox_loss: 0.0919 - val_mrcnn_mask_loss: 0.1770\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from config2 import *\n",
    "from dataset import NucleiDataset\n",
    "import numpy as np\n",
    "import model as modellib\n",
    "from model import log\n",
    "import utils\n",
    "import random\n",
    "\n",
    "# Training dataset\n",
    "dataset_train = NucleiDataset()\n",
    "dataset_train.add_nuclei(opt.train_data_root,'train')\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = NucleiDataset()\n",
    "dataset_val.add_nuclei(opt.val_data_root,'val')\n",
    "dataset_val.prepare()\n",
    "\n",
    "\"\"\"\n",
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    " \"\"\"   \n",
    "\n",
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=opt,\n",
    "                          model_dir=opt.MODEL_DIR)\n",
    "\n",
    "# Which weights to start with?\n",
    "# init_with = opt.init_with  # imagenet, coco, or last\n",
    "# init_with = \"last\"\n",
    "# if init_with == \"imagenet\":\n",
    "#     model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "# elif init_with == \"coco\":\n",
    "#     if not os.path.exists(opt.COCO_MODEL_PATH):\n",
    "#         utils.download_trained_weights(opt.COCO_MODEL_PATH)\n",
    "    \n",
    "#     # Load weights trained on MS COCO, but skip layers that\n",
    "#     # are different due to the different number of classes\n",
    "#     # See README for instructions to download the COCO weights\n",
    "#     model.load_weights(opt.COCO_MODEL_PATH, by_name=True,\n",
    "#                        exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "#                                 \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "# elif init_with == \"last\":\n",
    "#     # Load the last model you trained and continue training\n",
    "#     model_path = model.find_last()[1]\n",
    "#     print(\"Loading weights from \", model_path)\n",
    "#     model.load_weights(model.find_last()[1], by_name=True)\n",
    "    \n",
    "    \n",
    "model_path = \"checkpoints/nuclei20180302T0150/mask_rcnn_nuclei_0098.h5\"\n",
    "# model_path = \"C:\\Users\\Chevy\\Work\\Kaggle Data Science Bowl 2018\\Mask_RCNN-master\\Spot-Nuclei2\\checkpoints\\nuclei20180302T0150\\mask_rcnn_nuclei_0070.h5\"\n",
    "\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "# model_path = model.find_last()[1]\n",
    "# assert model_path != \"\", \"Provide path to trained weights\"\n",
    "\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)\n",
    "\n",
    "'''\n",
    "train\n",
    "\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers \n",
    "    (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, \n",
    "    pass layers='heads' to the train() function.\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. \n",
    "    Simply pass layers=\"all to train all layers.\n",
    "'''\n",
    "\n",
    "\n",
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\"\"\"\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=opt.LEARNING_RATE, \n",
    "            epochs=10, \n",
    "            layers='heads')\n",
    "\"\"\"\n",
    "\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=opt.LEARNING_RATE,\n",
    "#             epochs=40,\n",
    "#             layers='all')\n",
    "\n",
    "\n",
    "\n",
    "## Fine tune all layers\n",
    "## Passing layers=\"all\" trains all layers. You can also \n",
    "## pass a regular expression to select which layers to\n",
    "## train by name pattern.\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=opt.LEARNING_RATE/10,\n",
    "#             epochs=80, \n",
    "#             layers=\"all\")\n",
    "# # # 0\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=opt.LEARNING_RATE/100,\n",
    "            epochs=123,\n",
    "            layers='all')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
