{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDSM Mask RCNN training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chevy\\Documents\\GitHub\\Mammo_MaskRCNN\\mammography\n",
      "C:\\Users\\Chevy\\Documents\\GitHub\\Mammo_MaskRCNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chevy\\Anaconda3\\envs\\nnets\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "import imgaug\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "print(ROOT_DIR)\n",
    "# if ROOT_DIR.endswith(\"samples/nucleus\"):\n",
    "if ROOT_DIR.endswith(\"mammography\"):\n",
    "    # Go up one level to the repo root\n",
    "    ROOT_DIR = os.path.dirname(ROOT_DIR)\n",
    "    print(ROOT_DIR)\n",
    "    \n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "import mammo\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out to reload imported modules if they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directory\n",
    "# DATASET_DIR = os.path.join(ROOT_DIR, \"datasets/nucleus\")\n",
    "DATASET_DIR = os.path.join(ROOT_DIR, \"datasets/mammo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Image Count: 1878\n",
      "Class Count: 2\n",
      "  0. BG                                                \n",
      "  1. mass                                              \n",
      "val\n",
      "Images: 476\n",
      "Classes: ['BG', 'mass']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_train = mammo.MammoDataset()\n",
    "dataset_train.load_mammo(DATASET_DIR, subset=\"train\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset_train.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_train.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset_train.num_classes))\n",
    "for i, info in enumerate(dataset_train.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "    \n",
    "\n",
    "# Load validation dataset\n",
    "dataset_val = mammo.MammoDataset()\n",
    "dataset_val.load_mammo(DATASET_DIR, \"val\")\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset_val.image_ids), dataset_val.class_names))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [54.78 54.78 54.78]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           mammo\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         1000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (16, 32, 64, 128, 256)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.9\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1402\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               476\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  C:\\Users\\Chevy\\AppData\\Local\\Temp\\.keras\\models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: checkpoints\\mammo20180720T0204\\mask_rcnn_mammo_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chevy\\Anaconda3\\envs\\nnets\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/80\n",
      "1402/1402 [==============================] - 1213s 865ms/step - loss: 1.2020 - rpn_class_loss: 0.0344 - rpn_bbox_loss: 0.5430 - mrcnn_class_loss: 0.0264 - mrcnn_bbox_loss: 0.3033 - mrcnn_mask_loss: 0.2948 - val_loss: 1.3428 - val_rpn_class_loss: 0.0165 - val_rpn_bbox_loss: 0.4219 - val_mrcnn_class_loss: 0.0447 - val_mrcnn_bbox_loss: 0.4137 - val_mrcnn_mask_loss: 0.4460\n",
      "Epoch 2/80\n",
      "1402/1402 [==============================] - 1199s 855ms/step - loss: 1.2727 - rpn_class_loss: 0.0154 - rpn_bbox_loss: 0.4047 - mrcnn_class_loss: 0.0428 - mrcnn_bbox_loss: 0.3827 - mrcnn_mask_loss: 0.4271 - val_loss: 1.2557 - val_rpn_class_loss: 0.0143 - val_rpn_bbox_loss: 0.3786 - val_mrcnn_class_loss: 0.0509 - val_mrcnn_bbox_loss: 0.3854 - val_mrcnn_mask_loss: 0.4265\n",
      "Epoch 3/80\n",
      "1402/1402 [==============================] - 1182s 843ms/step - loss: 1.2866 - rpn_class_loss: 0.0119 - rpn_bbox_loss: 0.3734 - mrcnn_class_loss: 0.0650 - mrcnn_bbox_loss: 0.3998 - mrcnn_mask_loss: 0.4365 - val_loss: 1.4293 - val_rpn_class_loss: 0.0109 - val_rpn_bbox_loss: 0.4258 - val_mrcnn_class_loss: 0.0974 - val_mrcnn_bbox_loss: 0.4271 - val_mrcnn_mask_loss: 0.4680\n",
      "Epoch 4/80\n",
      "1402/1402 [==============================] - 1183s 844ms/step - loss: 1.2806 - rpn_class_loss: 0.0109 - rpn_bbox_loss: 0.3594 - mrcnn_class_loss: 0.0769 - mrcnn_bbox_loss: 0.4005 - mrcnn_mask_loss: 0.4328 - val_loss: 1.3643 - val_rpn_class_loss: 0.0103 - val_rpn_bbox_loss: 0.3792 - val_mrcnn_class_loss: 0.1030 - val_mrcnn_bbox_loss: 0.4228 - val_mrcnn_mask_loss: 0.4489\n",
      "Epoch 5/80\n",
      "1402/1402 [==============================] - 1184s 844ms/step - loss: 1.2903 - rpn_class_loss: 0.0096 - rpn_bbox_loss: 0.3439 - mrcnn_class_loss: 0.0880 - mrcnn_bbox_loss: 0.4019 - mrcnn_mask_loss: 0.4469 - val_loss: 1.3431 - val_rpn_class_loss: 0.0107 - val_rpn_bbox_loss: 0.3752 - val_mrcnn_class_loss: 0.0798 - val_mrcnn_bbox_loss: 0.4231 - val_mrcnn_mask_loss: 0.4543\n",
      "Epoch 6/80\n",
      "1402/1402 [==============================] - 1184s 844ms/step - loss: 1.2539 - rpn_class_loss: 0.0087 - rpn_bbox_loss: 0.3108 - mrcnn_class_loss: 0.0979 - mrcnn_bbox_loss: 0.3910 - mrcnn_mask_loss: 0.4455 - val_loss: 1.3535 - val_rpn_class_loss: 0.0084 - val_rpn_bbox_loss: 0.3768 - val_mrcnn_class_loss: 0.1079 - val_mrcnn_bbox_loss: 0.4182 - val_mrcnn_mask_loss: 0.4422\n",
      "Epoch 7/80\n",
      "1402/1402 [==============================] - 1184s 844ms/step - loss: 1.2326 - rpn_class_loss: 0.0083 - rpn_bbox_loss: 0.3054 - mrcnn_class_loss: 0.0952 - mrcnn_bbox_loss: 0.3819 - mrcnn_mask_loss: 0.4417 - val_loss: 1.3876 - val_rpn_class_loss: 0.0085 - val_rpn_bbox_loss: 0.3892 - val_mrcnn_class_loss: 0.1283 - val_mrcnn_bbox_loss: 0.4198 - val_mrcnn_mask_loss: 0.4418\n",
      "Epoch 8/80\n",
      "1402/1402 [==============================] - 1186s 846ms/step - loss: 1.2018 - rpn_class_loss: 0.0080 - rpn_bbox_loss: 0.2808 - mrcnn_class_loss: 0.1091 - mrcnn_bbox_loss: 0.3666 - mrcnn_mask_loss: 0.4372 - val_loss: 1.3908 - val_rpn_class_loss: 0.0075 - val_rpn_bbox_loss: 0.4153 - val_mrcnn_class_loss: 0.1341 - val_mrcnn_bbox_loss: 0.3996 - val_mrcnn_mask_loss: 0.4342\n",
      "Epoch 9/80\n",
      "1402/1402 [==============================] - 1183s 844ms/step - loss: 1.1777 - rpn_class_loss: 0.0072 - rpn_bbox_loss: 0.2636 - mrcnn_class_loss: 0.1184 - mrcnn_bbox_loss: 0.3548 - mrcnn_mask_loss: 0.4338 - val_loss: 1.4297 - val_rpn_class_loss: 0.0075 - val_rpn_bbox_loss: 0.4296 - val_mrcnn_class_loss: 0.1295 - val_mrcnn_bbox_loss: 0.4147 - val_mrcnn_mask_loss: 0.4485\n",
      "Epoch 10/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 1184s 844ms/step - loss: 1.1526 - rpn_class_loss: 0.0073 - rpn_bbox_loss: 0.2501 - mrcnn_class_loss: 0.1238 - mrcnn_bbox_loss: 0.3428 - mrcnn_mask_loss: 0.4287 - val_loss: 1.4214 - val_rpn_class_loss: 0.0078 - val_rpn_bbox_loss: 0.4279 - val_mrcnn_class_loss: 0.1332 - val_mrcnn_bbox_loss: 0.4174 - val_mrcnn_mask_loss: 0.4351\n",
      "Epoch 11/80\n",
      "1402/1402 [==============================] - 1182s 843ms/step - loss: 1.1304 - rpn_class_loss: 0.0069 - rpn_bbox_loss: 0.2395 - mrcnn_class_loss: 0.1325 - mrcnn_bbox_loss: 0.3290 - mrcnn_mask_loss: 0.4224 - val_loss: 1.4952 - val_rpn_class_loss: 0.0075 - val_rpn_bbox_loss: 0.5301 - val_mrcnn_class_loss: 0.1264 - val_mrcnn_bbox_loss: 0.4047 - val_mrcnn_mask_loss: 0.4266\n",
      "Epoch 12/80\n",
      "1402/1402 [==============================] - 1179s 841ms/step - loss: 1.1384 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.2476 - mrcnn_class_loss: 0.1408 - mrcnn_bbox_loss: 0.3235 - mrcnn_mask_loss: 0.4199 - val_loss: 1.4591 - val_rpn_class_loss: 0.0075 - val_rpn_bbox_loss: 0.4600 - val_mrcnn_class_loss: 0.1537 - val_mrcnn_bbox_loss: 0.4066 - val_mrcnn_mask_loss: 0.4314\n",
      "Epoch 13/80\n",
      "1402/1402 [==============================] - 1180s 841ms/step - loss: 1.0590 - rpn_class_loss: 0.0064 - rpn_bbox_loss: 0.2040 - mrcnn_class_loss: 0.1403 - mrcnn_bbox_loss: 0.2959 - mrcnn_mask_loss: 0.4124 - val_loss: 1.4516 - val_rpn_class_loss: 0.0076 - val_rpn_bbox_loss: 0.4210 - val_mrcnn_class_loss: 0.1614 - val_mrcnn_bbox_loss: 0.4269 - val_mrcnn_mask_loss: 0.4347\n",
      "Epoch 14/80\n",
      "1402/1402 [==============================] - 1186s 846ms/step - loss: 1.0452 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.1980 - mrcnn_class_loss: 0.1443 - mrcnn_bbox_loss: 0.2875 - mrcnn_mask_loss: 0.4094 - val_loss: 1.5192 - val_rpn_class_loss: 0.0078 - val_rpn_bbox_loss: 0.4909 - val_mrcnn_class_loss: 0.1621 - val_mrcnn_bbox_loss: 0.4260 - val_mrcnn_mask_loss: 0.4324\n",
      "Epoch 15/80\n",
      "1402/1402 [==============================] - 1185s 846ms/step - loss: 0.9908 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.1787 - mrcnn_class_loss: 0.1374 - mrcnn_bbox_loss: 0.2680 - mrcnn_mask_loss: 0.4008 - val_loss: 1.5563 - val_rpn_class_loss: 0.0079 - val_rpn_bbox_loss: 0.6026 - val_mrcnn_class_loss: 0.1327 - val_mrcnn_bbox_loss: 0.3964 - val_mrcnn_mask_loss: 0.4167\n",
      "Epoch 16/80\n",
      "1402/1402 [==============================] - 1183s 844ms/step - loss: 0.9743 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.1773 - mrcnn_class_loss: 0.1334 - mrcnn_bbox_loss: 0.2602 - mrcnn_mask_loss: 0.3971 - val_loss: 1.4695 - val_rpn_class_loss: 0.0076 - val_rpn_bbox_loss: 0.5025 - val_mrcnn_class_loss: 0.1394 - val_mrcnn_bbox_loss: 0.4023 - val_mrcnn_mask_loss: 0.4176\n",
      "Epoch 17/80\n",
      "1402/1402 [==============================] - 1183s 844ms/step - loss: 0.8931 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.1428 - mrcnn_class_loss: 0.1257 - mrcnn_bbox_loss: 0.2330 - mrcnn_mask_loss: 0.3855 - val_loss: 1.5125 - val_rpn_class_loss: 0.0076 - val_rpn_bbox_loss: 0.4883 - val_mrcnn_class_loss: 0.1696 - val_mrcnn_bbox_loss: 0.4197 - val_mrcnn_mask_loss: 0.4273\n",
      "Epoch 18/80\n",
      "1402/1402 [==============================] - 1182s 843ms/step - loss: 0.8820 - rpn_class_loss: 0.0054 - rpn_bbox_loss: 0.1352 - mrcnn_class_loss: 0.1313 - mrcnn_bbox_loss: 0.2248 - mrcnn_mask_loss: 0.3853 - val_loss: 1.6012 - val_rpn_class_loss: 0.0083 - val_rpn_bbox_loss: 0.6117 - val_mrcnn_class_loss: 0.1472 - val_mrcnn_bbox_loss: 0.4108 - val_mrcnn_mask_loss: 0.4232\n",
      "Epoch 19/80\n",
      "1402/1402 [==============================] - 1187s 847ms/step - loss: 0.8705 - rpn_class_loss: 0.0055 - rpn_bbox_loss: 0.1309 - mrcnn_class_loss: 0.1313 - mrcnn_bbox_loss: 0.2193 - mrcnn_mask_loss: 0.3834 - val_loss: 1.6423 - val_rpn_class_loss: 0.0077 - val_rpn_bbox_loss: 0.5770 - val_mrcnn_class_loss: 0.1739 - val_mrcnn_bbox_loss: 0.4352 - val_mrcnn_mask_loss: 0.4485\n",
      "Epoch 20/80\n",
      "1402/1402 [==============================] - 1182s 843ms/step - loss: 0.8276 - rpn_class_loss: 0.0052 - rpn_bbox_loss: 0.1208 - mrcnn_class_loss: 0.1223 - mrcnn_bbox_loss: 0.2052 - mrcnn_mask_loss: 0.3740 - val_loss: 1.6774 - val_rpn_class_loss: 0.0079 - val_rpn_bbox_loss: 0.6373 - val_mrcnn_class_loss: 0.1573 - val_mrcnn_bbox_loss: 0.4349 - val_mrcnn_mask_loss: 0.4399\n",
      "Epoch 21/80\n",
      "1402/1402 [==============================] - 1183s 844ms/step - loss: 0.7947 - rpn_class_loss: 0.0051 - rpn_bbox_loss: 0.1153 - mrcnn_class_loss: 0.1196 - mrcnn_bbox_loss: 0.1875 - mrcnn_mask_loss: 0.3672 - val_loss: 1.6740 - val_rpn_class_loss: 0.0079 - val_rpn_bbox_loss: 0.5521 - val_mrcnn_class_loss: 0.1946 - val_mrcnn_bbox_loss: 0.4585 - val_mrcnn_mask_loss: 0.4609\n",
      "Epoch 22/80\n",
      "1402/1402 [==============================] - 1183s 844ms/step - loss: 0.7354 - rpn_class_loss: 0.0049 - rpn_bbox_loss: 0.0952 - mrcnn_class_loss: 0.1084 - mrcnn_bbox_loss: 0.1721 - mrcnn_mask_loss: 0.3548 - val_loss: 1.8453 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.6944 - val_mrcnn_class_loss: 0.2102 - val_mrcnn_bbox_loss: 0.4507 - val_mrcnn_mask_loss: 0.4820\n",
      "Epoch 23/80\n",
      "1402/1402 [==============================] - 1187s 847ms/step - loss: 0.7440 - rpn_class_loss: 0.0052 - rpn_bbox_loss: 0.0943 - mrcnn_class_loss: 0.1145 - mrcnn_bbox_loss: 0.1743 - mrcnn_mask_loss: 0.3557 - val_loss: 1.6898 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.5566 - val_mrcnn_class_loss: 0.1864 - val_mrcnn_bbox_loss: 0.4390 - val_mrcnn_mask_loss: 0.4998\n",
      "Epoch 24/80\n",
      "1402/1402 [==============================] - 1208s 861ms/step - loss: 0.7053 - rpn_class_loss: 0.0047 - rpn_bbox_loss: 0.0905 - mrcnn_class_loss: 0.1055 - mrcnn_bbox_loss: 0.1591 - mrcnn_mask_loss: 0.3454 - val_loss: 1.8084 - val_rpn_class_loss: 0.0077 - val_rpn_bbox_loss: 0.7106 - val_mrcnn_class_loss: 0.1704 - val_mrcnn_bbox_loss: 0.4481 - val_mrcnn_mask_loss: 0.4716\n",
      "Epoch 25/80\n",
      "1402/1402 [==============================] - 1214s 866ms/step - loss: 0.6840 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.0880 - mrcnn_class_loss: 0.1024 - mrcnn_bbox_loss: 0.1497 - mrcnn_mask_loss: 0.3395 - val_loss: 1.7394 - val_rpn_class_loss: 0.0078 - val_rpn_bbox_loss: 0.6297 - val_mrcnn_class_loss: 0.1992 - val_mrcnn_bbox_loss: 0.4375 - val_mrcnn_mask_loss: 0.4652\n",
      "Epoch 26/80\n",
      "1402/1402 [==============================] - 1214s 866ms/step - loss: 0.6651 - rpn_class_loss: 0.0045 - rpn_bbox_loss: 0.0822 - mrcnn_class_loss: 0.0953 - mrcnn_bbox_loss: 0.1457 - mrcnn_mask_loss: 0.3373 - val_loss: 1.9577 - val_rpn_class_loss: 0.0082 - val_rpn_bbox_loss: 0.8964 - val_mrcnn_class_loss: 0.1817 - val_mrcnn_bbox_loss: 0.4160 - val_mrcnn_mask_loss: 0.4555\n",
      "Epoch 27/80\n",
      "1402/1402 [==============================] - 1216s 867ms/step - loss: 0.6249 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.0719 - mrcnn_class_loss: 0.0949 - mrcnn_bbox_loss: 0.1312 - mrcnn_mask_loss: 0.3226 - val_loss: 1.7792 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.5964 - val_mrcnn_class_loss: 0.2216 - val_mrcnn_bbox_loss: 0.4734 - val_mrcnn_mask_loss: 0.4799\n",
      "Epoch 28/80\n",
      "1402/1402 [==============================] - 1218s 869ms/step - loss: 0.6122 - rpn_class_loss: 0.0042 - rpn_bbox_loss: 0.0686 - mrcnn_class_loss: 0.0909 - mrcnn_bbox_loss: 0.1286 - mrcnn_mask_loss: 0.3199 - val_loss: 1.7465 - val_rpn_class_loss: 0.0087 - val_rpn_bbox_loss: 0.6549 - val_mrcnn_class_loss: 0.2058 - val_mrcnn_bbox_loss: 0.4176 - val_mrcnn_mask_loss: 0.4594\n",
      "Epoch 29/80\n",
      "1402/1402 [==============================] - 1219s 870ms/step - loss: 0.5940 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.0684 - mrcnn_class_loss: 0.0895 - mrcnn_bbox_loss: 0.1223 - mrcnn_mask_loss: 0.3099 - val_loss: 1.7866 - val_rpn_class_loss: 0.0081 - val_rpn_bbox_loss: 0.5897 - val_mrcnn_class_loss: 0.2383 - val_mrcnn_bbox_loss: 0.4336 - val_mrcnn_mask_loss: 0.5168\n",
      "Epoch 30/80\n",
      "1402/1402 [==============================] - 1219s 870ms/step - loss: 0.5948 - rpn_class_loss: 0.0041 - rpn_bbox_loss: 0.0744 - mrcnn_class_loss: 0.0820 - mrcnn_bbox_loss: 0.1207 - mrcnn_mask_loss: 0.3135 - val_loss: 1.8353 - val_rpn_class_loss: 0.0088 - val_rpn_bbox_loss: 0.5648 - val_mrcnn_class_loss: 0.2500 - val_mrcnn_bbox_loss: 0.4794 - val_mrcnn_mask_loss: 0.5322\n",
      "Epoch 31/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 1217s 868ms/step - loss: 0.5654 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.0633 - mrcnn_class_loss: 0.0839 - mrcnn_bbox_loss: 0.1102 - mrcnn_mask_loss: 0.3041 - val_loss: 1.9384 - val_rpn_class_loss: 0.0087 - val_rpn_bbox_loss: 0.6428 - val_mrcnn_class_loss: 0.2934 - val_mrcnn_bbox_loss: 0.4662 - val_mrcnn_mask_loss: 0.5274\n",
      "Epoch 32/80\n",
      "1402/1402 [==============================] - 1215s 867ms/step - loss: 0.5547 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.0593 - mrcnn_class_loss: 0.0779 - mrcnn_bbox_loss: 0.1109 - mrcnn_mask_loss: 0.3026 - val_loss: 1.9153 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.5752 - val_mrcnn_class_loss: 0.3209 - val_mrcnn_bbox_loss: 0.4531 - val_mrcnn_mask_loss: 0.5572\n",
      "Epoch 33/80\n",
      "1402/1402 [==============================] - 1216s 867ms/step - loss: 0.5249 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.0565 - mrcnn_class_loss: 0.0746 - mrcnn_bbox_loss: 0.1010 - mrcnn_mask_loss: 0.2893 - val_loss: 2.1208 - val_rpn_class_loss: 0.0097 - val_rpn_bbox_loss: 0.6365 - val_mrcnn_class_loss: 0.3903 - val_mrcnn_bbox_loss: 0.4755 - val_mrcnn_mask_loss: 0.6089\n",
      "Epoch 34/80\n",
      "1402/1402 [==============================] - 1206s 860ms/step - loss: 0.5218 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.0565 - mrcnn_class_loss: 0.0768 - mrcnn_bbox_loss: 0.0968 - mrcnn_mask_loss: 0.2882 - val_loss: 1.9273 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.6179 - val_mrcnn_class_loss: 0.3151 - val_mrcnn_bbox_loss: 0.4532 - val_mrcnn_mask_loss: 0.5331\n",
      "Epoch 35/80\n",
      "1402/1402 [==============================] - 1187s 847ms/step - loss: 0.5093 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.0572 - mrcnn_class_loss: 0.0703 - mrcnn_bbox_loss: 0.0960 - mrcnn_mask_loss: 0.2822 - val_loss: 2.0644 - val_rpn_class_loss: 0.0095 - val_rpn_bbox_loss: 0.6624 - val_mrcnn_class_loss: 0.3142 - val_mrcnn_bbox_loss: 0.4759 - val_mrcnn_mask_loss: 0.6023\n",
      "Epoch 36/80\n",
      "1402/1402 [==============================] - 1181s 842ms/step - loss: 0.4880 - rpn_class_loss: 0.0032 - rpn_bbox_loss: 0.0552 - mrcnn_class_loss: 0.0649 - mrcnn_bbox_loss: 0.0908 - mrcnn_mask_loss: 0.2738 - val_loss: 2.1279 - val_rpn_class_loss: 0.0086 - val_rpn_bbox_loss: 0.7338 - val_mrcnn_class_loss: 0.3804 - val_mrcnn_bbox_loss: 0.4555 - val_mrcnn_mask_loss: 0.5496\n",
      "Epoch 37/80\n",
      "1402/1402 [==============================] - 1196s 853ms/step - loss: 0.4658 - rpn_class_loss: 0.0029 - rpn_bbox_loss: 0.0470 - mrcnn_class_loss: 0.0684 - mrcnn_bbox_loss: 0.0826 - mrcnn_mask_loss: 0.2648 - val_loss: 2.2502 - val_rpn_class_loss: 0.0100 - val_rpn_bbox_loss: 0.8536 - val_mrcnn_class_loss: 0.3577 - val_mrcnn_bbox_loss: 0.4475 - val_mrcnn_mask_loss: 0.5813\n",
      "Epoch 38/80\n",
      "1402/1402 [==============================] - 1197s 854ms/step - loss: 0.4647 - rpn_class_loss: 0.0034 - rpn_bbox_loss: 0.0531 - mrcnn_class_loss: 0.0596 - mrcnn_bbox_loss: 0.0824 - mrcnn_mask_loss: 0.2661 - val_loss: 2.1688 - val_rpn_class_loss: 0.0096 - val_rpn_bbox_loss: 0.5960 - val_mrcnn_class_loss: 0.4632 - val_mrcnn_bbox_loss: 0.4476 - val_mrcnn_mask_loss: 0.6523\n",
      "Epoch 39/80\n",
      "1402/1402 [==============================] - 1182s 843ms/step - loss: 0.4525 - rpn_class_loss: 0.0030 - rpn_bbox_loss: 0.0458 - mrcnn_class_loss: 0.0618 - mrcnn_bbox_loss: 0.0797 - mrcnn_mask_loss: 0.2621 - val_loss: 2.2612 - val_rpn_class_loss: 0.0105 - val_rpn_bbox_loss: 0.5619 - val_mrcnn_class_loss: 0.4887 - val_mrcnn_bbox_loss: 0.4855 - val_mrcnn_mask_loss: 0.7145\n",
      "Epoch 40/80\n",
      "1402/1402 [==============================] - 1183s 844ms/step - loss: 0.4389 - rpn_class_loss: 0.0028 - rpn_bbox_loss: 0.0456 - mrcnn_class_loss: 0.0558 - mrcnn_bbox_loss: 0.0760 - mrcnn_mask_loss: 0.2586 - val_loss: 2.2684 - val_rpn_class_loss: 0.0095 - val_rpn_bbox_loss: 0.7971 - val_mrcnn_class_loss: 0.4352 - val_mrcnn_bbox_loss: 0.4455 - val_mrcnn_mask_loss: 0.5811\n",
      "Epoch 41/80\n",
      "1402/1402 [==============================] - 1184s 845ms/step - loss: 0.4298 - rpn_class_loss: 0.0030 - rpn_bbox_loss: 0.0429 - mrcnn_class_loss: 0.0571 - mrcnn_bbox_loss: 0.0740 - mrcnn_mask_loss: 0.2528 - val_loss: 2.3202 - val_rpn_class_loss: 0.0103 - val_rpn_bbox_loss: 0.8408 - val_mrcnn_class_loss: 0.4419 - val_mrcnn_bbox_loss: 0.4351 - val_mrcnn_mask_loss: 0.5920\n",
      "Epoch 42/80\n",
      "1402/1402 [==============================] - 1178s 840ms/step - loss: 0.4191 - rpn_class_loss: 0.0028 - rpn_bbox_loss: 0.0418 - mrcnn_class_loss: 0.0528 - mrcnn_bbox_loss: 0.0728 - mrcnn_mask_loss: 0.2489 - val_loss: 2.1067 - val_rpn_class_loss: 0.0098 - val_rpn_bbox_loss: 0.5324 - val_mrcnn_class_loss: 0.4300 - val_mrcnn_bbox_loss: 0.4811 - val_mrcnn_mask_loss: 0.6534\n",
      "Epoch 43/80\n",
      "1402/1402 [==============================] - 1181s 842ms/step - loss: 0.4106 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0436 - mrcnn_class_loss: 0.0469 - mrcnn_bbox_loss: 0.0706 - mrcnn_mask_loss: 0.2469 - val_loss: 2.1137 - val_rpn_class_loss: 0.0092 - val_rpn_bbox_loss: 0.7127 - val_mrcnn_class_loss: 0.3823 - val_mrcnn_bbox_loss: 0.4526 - val_mrcnn_mask_loss: 0.5570\n",
      "Epoch 44/80\n",
      "1402/1402 [==============================] - 1179s 841ms/step - loss: 0.3971 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0446 - mrcnn_class_loss: 0.0461 - mrcnn_bbox_loss: 0.0664 - mrcnn_mask_loss: 0.2372 - val_loss: 2.3250 - val_rpn_class_loss: 0.0105 - val_rpn_bbox_loss: 0.6402 - val_mrcnn_class_loss: 0.5420 - val_mrcnn_bbox_loss: 0.4323 - val_mrcnn_mask_loss: 0.6999\n",
      "Epoch 45/80\n",
      "1402/1402 [==============================] - 1180s 842ms/step - loss: 0.3861 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0396 - mrcnn_class_loss: 0.0445 - mrcnn_bbox_loss: 0.0640 - mrcnn_mask_loss: 0.2354 - val_loss: 2.3325 - val_rpn_class_loss: 0.0108 - val_rpn_bbox_loss: 0.6656 - val_mrcnn_class_loss: 0.5282 - val_mrcnn_bbox_loss: 0.4753 - val_mrcnn_mask_loss: 0.6526\n",
      "Epoch 46/80\n",
      "1402/1402 [==============================] - 1181s 842ms/step - loss: 0.3806 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0370 - mrcnn_class_loss: 0.0471 - mrcnn_bbox_loss: 0.0625 - mrcnn_mask_loss: 0.2314 - val_loss: 2.3149 - val_rpn_class_loss: 0.0104 - val_rpn_bbox_loss: 0.6249 - val_mrcnn_class_loss: 0.5320 - val_mrcnn_bbox_loss: 0.4677 - val_mrcnn_mask_loss: 0.6799\n",
      "Epoch 47/80\n",
      "1402/1402 [==============================] - 1180s 842ms/step - loss: 0.3706 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0359 - mrcnn_class_loss: 0.0447 - mrcnn_bbox_loss: 0.0586 - mrcnn_mask_loss: 0.2290 - val_loss: 2.3877 - val_rpn_class_loss: 0.0112 - val_rpn_bbox_loss: 0.6599 - val_mrcnn_class_loss: 0.5283 - val_mrcnn_bbox_loss: 0.4436 - val_mrcnn_mask_loss: 0.7448\n",
      "Epoch 48/80\n",
      "1402/1402 [==============================] - 1178s 840ms/step - loss: 0.3712 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0365 - mrcnn_class_loss: 0.0427 - mrcnn_bbox_loss: 0.0618 - mrcnn_mask_loss: 0.2277 - val_loss: 2.4648 - val_rpn_class_loss: 0.0113 - val_rpn_bbox_loss: 0.8136 - val_mrcnn_class_loss: 0.4820 - val_mrcnn_bbox_loss: 0.4532 - val_mrcnn_mask_loss: 0.7047\n",
      "Epoch 49/80\n",
      "1402/1402 [==============================] - 1180s 842ms/step - loss: 0.3571 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0376 - mrcnn_class_loss: 0.0408 - mrcnn_bbox_loss: 0.0567 - mrcnn_mask_loss: 0.2196 - val_loss: 2.4236 - val_rpn_class_loss: 0.0107 - val_rpn_bbox_loss: 0.5472 - val_mrcnn_class_loss: 0.5882 - val_mrcnn_bbox_loss: 0.4700 - val_mrcnn_mask_loss: 0.8073\n",
      "Epoch 50/80\n",
      "1402/1402 [==============================] - 1178s 840ms/step - loss: 0.3499 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0346 - mrcnn_class_loss: 0.0394 - mrcnn_bbox_loss: 0.0546 - mrcnn_mask_loss: 0.2189 - val_loss: 2.4963 - val_rpn_class_loss: 0.0109 - val_rpn_bbox_loss: 0.8112 - val_mrcnn_class_loss: 0.5750 - val_mrcnn_bbox_loss: 0.4351 - val_mrcnn_mask_loss: 0.6642\n",
      "Epoch 51/80\n",
      "1402/1402 [==============================] - 1180s 842ms/step - loss: 0.3505 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0339 - mrcnn_class_loss: 0.0418 - mrcnn_bbox_loss: 0.0562 - mrcnn_mask_loss: 0.2165 - val_loss: 2.4216 - val_rpn_class_loss: 0.0110 - val_rpn_bbox_loss: 0.7719 - val_mrcnn_class_loss: 0.5684 - val_mrcnn_bbox_loss: 0.4482 - val_mrcnn_mask_loss: 0.6221\n",
      "Epoch 52/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 1181s 842ms/step - loss: 0.3273 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0301 - mrcnn_class_loss: 0.0359 - mrcnn_bbox_loss: 0.0520 - mrcnn_mask_loss: 0.2071 - val_loss: 2.6610 - val_rpn_class_loss: 0.0125 - val_rpn_bbox_loss: 0.6657 - val_mrcnn_class_loss: 0.6758 - val_mrcnn_bbox_loss: 0.4670 - val_mrcnn_mask_loss: 0.8400\n",
      "Epoch 53/80\n",
      "1402/1402 [==============================] - 1202s 857ms/step - loss: 0.3310 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0319 - mrcnn_class_loss: 0.0367 - mrcnn_bbox_loss: 0.0522 - mrcnn_mask_loss: 0.2081 - val_loss: 2.3266 - val_rpn_class_loss: 0.0113 - val_rpn_bbox_loss: 0.6081 - val_mrcnn_class_loss: 0.6047 - val_mrcnn_bbox_loss: 0.4648 - val_mrcnn_mask_loss: 0.6377\n",
      "Epoch 54/80\n",
      "1402/1402 [==============================] - 1200s 856ms/step - loss: 0.3219 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0306 - mrcnn_class_loss: 0.0360 - mrcnn_bbox_loss: 0.0508 - mrcnn_mask_loss: 0.2025 - val_loss: 2.4484 - val_rpn_class_loss: 0.0117 - val_rpn_bbox_loss: 0.6735 - val_mrcnn_class_loss: 0.6060 - val_mrcnn_bbox_loss: 0.4511 - val_mrcnn_mask_loss: 0.7061\n",
      "Epoch 55/80\n",
      "1402/1402 [==============================] - 1202s 858ms/step - loss: 0.3160 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0311 - mrcnn_class_loss: 0.0349 - mrcnn_bbox_loss: 0.0489 - mrcnn_mask_loss: 0.1990 - val_loss: 2.5599 - val_rpn_class_loss: 0.0118 - val_rpn_bbox_loss: 0.6877 - val_mrcnn_class_loss: 0.6362 - val_mrcnn_bbox_loss: 0.4574 - val_mrcnn_mask_loss: 0.7667\n",
      "Epoch 56/80\n",
      "1402/1402 [==============================] - 1202s 857ms/step - loss: 0.3093 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0304 - mrcnn_class_loss: 0.0327 - mrcnn_bbox_loss: 0.0477 - mrcnn_mask_loss: 0.1967 - val_loss: 2.4790 - val_rpn_class_loss: 0.0113 - val_rpn_bbox_loss: 0.6640 - val_mrcnn_class_loss: 0.6227 - val_mrcnn_bbox_loss: 0.4573 - val_mrcnn_mask_loss: 0.7238\n",
      "Epoch 57/80\n",
      "1402/1402 [==============================] - 1210s 863ms/step - loss: 0.3017 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0275 - mrcnn_class_loss: 0.0330 - mrcnn_bbox_loss: 0.0448 - mrcnn_mask_loss: 0.1945 - val_loss: 2.7741 - val_rpn_class_loss: 0.0128 - val_rpn_bbox_loss: 1.0455 - val_mrcnn_class_loss: 0.5935 - val_mrcnn_bbox_loss: 0.4428 - val_mrcnn_mask_loss: 0.6795\n",
      "Epoch 58/80\n",
      "1402/1402 [==============================] - 1213s 865ms/step - loss: 0.3029 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0305 - mrcnn_class_loss: 0.0333 - mrcnn_bbox_loss: 0.0448 - mrcnn_mask_loss: 0.1925 - val_loss: 2.6934 - val_rpn_class_loss: 0.0123 - val_rpn_bbox_loss: 0.8527 - val_mrcnn_class_loss: 0.6203 - val_mrcnn_bbox_loss: 0.4292 - val_mrcnn_mask_loss: 0.7789\n",
      "Epoch 59/80\n",
      "1402/1402 [==============================] - 1213s 865ms/step - loss: 0.2914 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0271 - mrcnn_class_loss: 0.0317 - mrcnn_bbox_loss: 0.0433 - mrcnn_mask_loss: 0.1875 - val_loss: 2.4947 - val_rpn_class_loss: 0.0129 - val_rpn_bbox_loss: 0.7150 - val_mrcnn_class_loss: 0.6589 - val_mrcnn_bbox_loss: 0.4328 - val_mrcnn_mask_loss: 0.6751\n",
      "Epoch 60/80\n",
      "1402/1402 [==============================] - 1216s 867ms/step - loss: 0.2913 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0278 - mrcnn_class_loss: 0.0311 - mrcnn_bbox_loss: 0.0427 - mrcnn_mask_loss: 0.1881 - val_loss: 2.5502 - val_rpn_class_loss: 0.0128 - val_rpn_bbox_loss: 0.6651 - val_mrcnn_class_loss: 0.5567 - val_mrcnn_bbox_loss: 0.4602 - val_mrcnn_mask_loss: 0.8554\n",
      "Epoch 61/80\n",
      "1402/1402 [==============================] - 1225s 874ms/step - loss: 0.2782 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0253 - mrcnn_class_loss: 0.0306 - mrcnn_bbox_loss: 0.0412 - mrcnn_mask_loss: 0.1795 - val_loss: 2.6472 - val_rpn_class_loss: 0.0128 - val_rpn_bbox_loss: 0.7340 - val_mrcnn_class_loss: 0.5844 - val_mrcnn_bbox_loss: 0.4461 - val_mrcnn_mask_loss: 0.8700\n",
      "Epoch 62/80\n",
      "1402/1402 [==============================] - 1225s 873ms/step - loss: 0.2816 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0268 - mrcnn_class_loss: 0.0305 - mrcnn_bbox_loss: 0.0420 - mrcnn_mask_loss: 0.1807 - val_loss: 2.5063 - val_rpn_class_loss: 0.0128 - val_rpn_bbox_loss: 0.6349 - val_mrcnn_class_loss: 0.6220 - val_mrcnn_bbox_loss: 0.4640 - val_mrcnn_mask_loss: 0.7725\n",
      "Epoch 63/80\n",
      "1402/1402 [==============================] - 1226s 874ms/step - loss: 0.2725 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0254 - mrcnn_class_loss: 0.0289 - mrcnn_bbox_loss: 0.0391 - mrcnn_mask_loss: 0.1774 - val_loss: 2.5721 - val_rpn_class_loss: 0.0119 - val_rpn_bbox_loss: 0.7240 - val_mrcnn_class_loss: 0.6033 - val_mrcnn_bbox_loss: 0.4671 - val_mrcnn_mask_loss: 0.7657\n",
      "Epoch 64/80\n",
      "1402/1402 [==============================] - 1227s 875ms/step - loss: 0.2667 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0254 - mrcnn_class_loss: 0.0284 - mrcnn_bbox_loss: 0.0369 - mrcnn_mask_loss: 0.1745 - val_loss: 2.7177 - val_rpn_class_loss: 0.0140 - val_rpn_bbox_loss: 0.6128 - val_mrcnn_class_loss: 0.7162 - val_mrcnn_bbox_loss: 0.4628 - val_mrcnn_mask_loss: 0.9120\n",
      "Epoch 65/80\n",
      "1402/1402 [==============================] - 1227s 875ms/step - loss: 0.2662 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0249 - mrcnn_class_loss: 0.0298 - mrcnn_bbox_loss: 0.0375 - mrcnn_mask_loss: 0.1726 - val_loss: 2.6648 - val_rpn_class_loss: 0.0142 - val_rpn_bbox_loss: 0.6869 - val_mrcnn_class_loss: 0.6508 - val_mrcnn_bbox_loss: 0.4477 - val_mrcnn_mask_loss: 0.8653\n",
      "Epoch 66/80\n",
      "1402/1402 [==============================] - 1228s 876ms/step - loss: 0.2601 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0239 - mrcnn_class_loss: 0.0272 - mrcnn_bbox_loss: 0.0374 - mrcnn_mask_loss: 0.1701 - val_loss: 2.6502 - val_rpn_class_loss: 0.0134 - val_rpn_bbox_loss: 0.6755 - val_mrcnn_class_loss: 0.6336 - val_mrcnn_bbox_loss: 0.4530 - val_mrcnn_mask_loss: 0.8747\n",
      "Epoch 67/80\n",
      "1402/1402 [==============================] - 1229s 877ms/step - loss: 0.2570 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0232 - mrcnn_class_loss: 0.0297 - mrcnn_bbox_loss: 0.0350 - mrcnn_mask_loss: 0.1677 - val_loss: 2.7709 - val_rpn_class_loss: 0.0139 - val_rpn_bbox_loss: 0.8164 - val_mrcnn_class_loss: 0.7236 - val_mrcnn_bbox_loss: 0.4359 - val_mrcnn_mask_loss: 0.7811\n",
      "Epoch 68/80\n",
      "1402/1402 [==============================] - 1220s 870ms/step - loss: 0.2521 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0221 - mrcnn_class_loss: 0.0264 - mrcnn_bbox_loss: 0.0356 - mrcnn_mask_loss: 0.1667 - val_loss: 2.9118 - val_rpn_class_loss: 0.0138 - val_rpn_bbox_loss: 0.6400 - val_mrcnn_class_loss: 0.8486 - val_mrcnn_bbox_loss: 0.4666 - val_mrcnn_mask_loss: 0.9427\n",
      "Epoch 69/80\n",
      "1402/1402 [==============================] - 1207s 861ms/step - loss: 0.2484 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0221 - mrcnn_class_loss: 0.0261 - mrcnn_bbox_loss: 0.0357 - mrcnn_mask_loss: 0.1631 - val_loss: 2.8281 - val_rpn_class_loss: 0.0156 - val_rpn_bbox_loss: 0.6769 - val_mrcnn_class_loss: 0.7907 - val_mrcnn_bbox_loss: 0.4394 - val_mrcnn_mask_loss: 0.9055\n",
      "Epoch 70/80\n",
      "1402/1402 [==============================] - 1215s 867ms/step - loss: 0.2448 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0212 - mrcnn_class_loss: 0.0262 - mrcnn_bbox_loss: 0.0337 - mrcnn_mask_loss: 0.1623 - val_loss: 2.7184 - val_rpn_class_loss: 0.0142 - val_rpn_bbox_loss: 0.6975 - val_mrcnn_class_loss: 0.7556 - val_mrcnn_bbox_loss: 0.4525 - val_mrcnn_mask_loss: 0.7985\n",
      "Epoch 71/80\n",
      "1402/1402 [==============================] - 1205s 860ms/step - loss: 0.2356 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0202 - mrcnn_class_loss: 0.0248 - mrcnn_bbox_loss: 0.0318 - mrcnn_mask_loss: 0.1576 - val_loss: 2.7847 - val_rpn_class_loss: 0.0149 - val_rpn_bbox_loss: 0.6028 - val_mrcnn_class_loss: 0.8352 - val_mrcnn_bbox_loss: 0.4755 - val_mrcnn_mask_loss: 0.8561\n",
      "Epoch 72/80\n",
      "1402/1402 [==============================] - 1208s 861ms/step - loss: 0.2389 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0216 - mrcnn_class_loss: 0.0263 - mrcnn_bbox_loss: 0.0323 - mrcnn_mask_loss: 0.1574 - val_loss: 2.6355 - val_rpn_class_loss: 0.0149 - val_rpn_bbox_loss: 0.6417 - val_mrcnn_class_loss: 0.6310 - val_mrcnn_bbox_loss: 0.4628 - val_mrcnn_mask_loss: 0.8850\n",
      "Epoch 73/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 1205s 859ms/step - loss: 0.2264 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0210 - mrcnn_class_loss: 0.0225 - mrcnn_bbox_loss: 0.0305 - mrcnn_mask_loss: 0.1512 - val_loss: 2.7970 - val_rpn_class_loss: 0.0154 - val_rpn_bbox_loss: 0.6355 - val_mrcnn_class_loss: 0.6779 - val_mrcnn_bbox_loss: 0.4563 - val_mrcnn_mask_loss: 1.0118\n",
      "Epoch 74/80\n",
      "1402/1402 [==============================] - 1202s 857ms/step - loss: 0.2260 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0207 - mrcnn_class_loss: 0.0234 - mrcnn_bbox_loss: 0.0296 - mrcnn_mask_loss: 0.1512 - val_loss: 2.8190 - val_rpn_class_loss: 0.0164 - val_rpn_bbox_loss: 0.6178 - val_mrcnn_class_loss: 0.8066 - val_mrcnn_bbox_loss: 0.4472 - val_mrcnn_mask_loss: 0.9309\n",
      "Epoch 75/80\n",
      "1402/1402 [==============================] - 1202s 857ms/step - loss: 0.2288 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0208 - mrcnn_class_loss: 0.0249 - mrcnn_bbox_loss: 0.0303 - mrcnn_mask_loss: 0.1518 - val_loss: 2.7882 - val_rpn_class_loss: 0.0161 - val_rpn_bbox_loss: 0.6696 - val_mrcnn_class_loss: 0.6625 - val_mrcnn_bbox_loss: 0.4423 - val_mrcnn_mask_loss: 0.9977\n",
      "Epoch 76/80\n",
      "1402/1402 [==============================] - 1201s 857ms/step - loss: 0.2209 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0206 - mrcnn_class_loss: 0.0232 - mrcnn_bbox_loss: 0.0288 - mrcnn_mask_loss: 0.1474 - val_loss: 2.8909 - val_rpn_class_loss: 0.0142 - val_rpn_bbox_loss: 0.6247 - val_mrcnn_class_loss: 0.7632 - val_mrcnn_bbox_loss: 0.4639 - val_mrcnn_mask_loss: 1.0249\n",
      "Epoch 77/80\n",
      "1402/1402 [==============================] - 1189s 848ms/step - loss: 0.2225 - rpn_class_loss: 9.9997e-04 - rpn_bbox_loss: 0.0201 - mrcnn_class_loss: 0.0227 - mrcnn_bbox_loss: 0.0296 - mrcnn_mask_loss: 0.1490 - val_loss: 2.7958 - val_rpn_class_loss: 0.0153 - val_rpn_bbox_loss: 0.6986 - val_mrcnn_class_loss: 0.7522 - val_mrcnn_bbox_loss: 0.4583 - val_mrcnn_mask_loss: 0.8714\n",
      "Epoch 78/80\n",
      "1402/1402 [==============================] - 1179s 841ms/step - loss: 0.2148 - rpn_class_loss: 9.7327e-04 - rpn_bbox_loss: 0.0198 - mrcnn_class_loss: 0.0219 - mrcnn_bbox_loss: 0.0280 - mrcnn_mask_loss: 0.1442 - val_loss: 2.8616 - val_rpn_class_loss: 0.0157 - val_rpn_bbox_loss: 0.8206 - val_mrcnn_class_loss: 0.7383 - val_mrcnn_bbox_loss: 0.4430 - val_mrcnn_mask_loss: 0.8440\n",
      "Epoch 79/80\n",
      "1402/1402 [==============================] - 1180s 842ms/step - loss: 0.2142 - rpn_class_loss: 9.2270e-04 - rpn_bbox_loss: 0.0177 - mrcnn_class_loss: 0.0229 - mrcnn_bbox_loss: 0.0279 - mrcnn_mask_loss: 0.1449 - val_loss: 3.1249 - val_rpn_class_loss: 0.0170 - val_rpn_bbox_loss: 0.7440 - val_mrcnn_class_loss: 0.8617 - val_mrcnn_bbox_loss: 0.4520 - val_mrcnn_mask_loss: 1.0501\n",
      "Epoch 80/80\n",
      "1402/1402 [==============================] - 1178s 841ms/step - loss: 0.2126 - rpn_class_loss: 8.9218e-04 - rpn_bbox_loss: 0.0190 - mrcnn_class_loss: 0.0210 - mrcnn_bbox_loss: 0.0280 - mrcnn_mask_loss: 0.1437 - val_loss: 2.9351 - val_rpn_class_loss: 0.0169 - val_rpn_bbox_loss: 0.6827 - val_mrcnn_class_loss: 0.8239 - val_mrcnn_bbox_loss: 0.4458 - val_mrcnn_mask_loss: 0.9658\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "# Use configuation from mammo.py, but override\n",
    "# image resizing so we see the real sizes here\n",
    "class NoResizeConfig(mammo.MammoConfig):\n",
    "#     IMAGE_RESIZE_MODE = \"none\"\n",
    "#     USE_MINI_MASK = False\n",
    "    # Adjust depending on your GPU memory\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + mass\n",
    "\n",
    "    # Number of training and validation steps per epoch\n",
    "    STEPS_PER_EPOCH = (len(dataset_train.image_ids) - len(dataset_val.image_ids)) // IMAGES_PER_GPU\n",
    "    VALIDATION_STEPS = max(1, len(dataset_val.image_ids) // IMAGES_PER_GPU)\n",
    "    \n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 256\n",
    "    \n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 1000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "    \n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "    \n",
    "config = NoResizeConfig()\n",
    "config.display()\n",
    "\n",
    "MODEL_DIR = 'checkpoints'\n",
    "\n",
    "# Create model\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,                          \n",
    "                          model_dir=MODEL_DIR)\n",
    "# Select weights file to load\n",
    "weights_path = model.get_imagenet_weights()\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "model.train(dataset_train, dataset_val, config.LEARNING_RATE, epochs=80, layers='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [54.78 54.78 54.78]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           mammo\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         1000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (16, 32, 64, 128, 256)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.9\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    512\n",
      "STEPS_PER_EPOCH                1402\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               476\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  C:\\Users\\Chevy\\AppData\\Local\\Temp\\.keras\\models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: checkpoints\\mammo20180718T0053\\mask_rcnn_mammo_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chevy\\Anaconda3\\envs\\nnets\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/60\n",
      "1402/1402 [==============================] - 1238s 883ms/step - loss: 1.1470 - rpn_class_loss: 0.0214 - rpn_bbox_loss: 0.5230 - mrcnn_class_loss: 0.0263 - mrcnn_bbox_loss: 0.2870 - mrcnn_mask_loss: 0.2892 - val_loss: 1.2862 - val_rpn_class_loss: 0.0146 - val_rpn_bbox_loss: 0.4527 - val_mrcnn_class_loss: 0.0481 - val_mrcnn_bbox_loss: 0.3543 - val_mrcnn_mask_loss: 0.4165\n",
      "Epoch 2/60\n",
      "1402/1402 [==============================] - 1237s 883ms/step - loss: 1.2175 - rpn_class_loss: 0.0098 - rpn_bbox_loss: 0.4041 - mrcnn_class_loss: 0.0437 - mrcnn_bbox_loss: 0.3654 - mrcnn_mask_loss: 0.3944 - val_loss: 1.2069 - val_rpn_class_loss: 0.0093 - val_rpn_bbox_loss: 0.3761 - val_mrcnn_class_loss: 0.0501 - val_mrcnn_bbox_loss: 0.3659 - val_mrcnn_mask_loss: 0.4054\n",
      "Epoch 3/60\n",
      "1402/1402 [==============================] - 1238s 883ms/step - loss: 1.2203 - rpn_class_loss: 0.0088 - rpn_bbox_loss: 0.3787 - mrcnn_class_loss: 0.0548 - mrcnn_bbox_loss: 0.3739 - mrcnn_mask_loss: 0.4040 - val_loss: 1.3247 - val_rpn_class_loss: 0.0078 - val_rpn_bbox_loss: 0.3802 - val_mrcnn_class_loss: 0.0783 - val_mrcnn_bbox_loss: 0.4301 - val_mrcnn_mask_loss: 0.4282\n",
      "Epoch 4/60\n",
      "1402/1402 [==============================] - 1239s 884ms/step - loss: 1.2548 - rpn_class_loss: 0.0076 - rpn_bbox_loss: 0.3594 - mrcnn_class_loss: 0.0690 - mrcnn_bbox_loss: 0.3928 - mrcnn_mask_loss: 0.4259 - val_loss: 1.3479 - val_rpn_class_loss: 0.0070 - val_rpn_bbox_loss: 0.3625 - val_mrcnn_class_loss: 0.0689 - val_mrcnn_bbox_loss: 0.4092 - val_mrcnn_mask_loss: 0.5002\n",
      "Epoch 5/60\n",
      "1402/1402 [==============================] - 1238s 883ms/step - loss: 1.2708 - rpn_class_loss: 0.0065 - rpn_bbox_loss: 0.3360 - mrcnn_class_loss: 0.0857 - mrcnn_bbox_loss: 0.3992 - mrcnn_mask_loss: 0.4434 - val_loss: 1.3312 - val_rpn_class_loss: 0.0063 - val_rpn_bbox_loss: 0.3518 - val_mrcnn_class_loss: 0.0964 - val_mrcnn_bbox_loss: 0.4232 - val_mrcnn_mask_loss: 0.4535\n",
      "Epoch 6/60\n",
      "1402/1402 [==============================] - 1207s 861ms/step - loss: 1.2187 - rpn_class_loss: 0.0062 - rpn_bbox_loss: 0.3089 - mrcnn_class_loss: 0.0936 - mrcnn_bbox_loss: 0.3742 - mrcnn_mask_loss: 0.4358 - val_loss: 1.3853 - val_rpn_class_loss: 0.0059 - val_rpn_bbox_loss: 0.3873 - val_mrcnn_class_loss: 0.1119 - val_mrcnn_bbox_loss: 0.4264 - val_mrcnn_mask_loss: 0.4537\n",
      "Epoch 7/60\n",
      "1402/1402 [==============================] - 1204s 859ms/step - loss: 1.2553 - rpn_class_loss: 0.0053 - rpn_bbox_loss: 0.3079 - mrcnn_class_loss: 0.1036 - mrcnn_bbox_loss: 0.3939 - mrcnn_mask_loss: 0.4446 - val_loss: 1.4124 - val_rpn_class_loss: 0.0059 - val_rpn_bbox_loss: 0.4248 - val_mrcnn_class_loss: 0.1221 - val_mrcnn_bbox_loss: 0.4042 - val_mrcnn_mask_loss: 0.4555\n",
      "Epoch 8/60\n",
      "1402/1402 [==============================] - 1205s 860ms/step - loss: 1.2121 - rpn_class_loss: 0.0054 - rpn_bbox_loss: 0.2898 - mrcnn_class_loss: 0.1117 - mrcnn_bbox_loss: 0.3690 - mrcnn_mask_loss: 0.4362 - val_loss: 1.3747 - val_rpn_class_loss: 0.0052 - val_rpn_bbox_loss: 0.3986 - val_mrcnn_class_loss: 0.1158 - val_mrcnn_bbox_loss: 0.4209 - val_mrcnn_mask_loss: 0.4341\n",
      "Epoch 9/60\n",
      "1402/1402 [==============================] - 1209s 862ms/step - loss: 1.1786 - rpn_class_loss: 0.0050 - rpn_bbox_loss: 0.2735 - mrcnn_class_loss: 0.1173 - mrcnn_bbox_loss: 0.3525 - mrcnn_mask_loss: 0.4302 - val_loss: 1.3643 - val_rpn_class_loss: 0.0050 - val_rpn_bbox_loss: 0.3939 - val_mrcnn_class_loss: 0.1222 - val_mrcnn_bbox_loss: 0.4092 - val_mrcnn_mask_loss: 0.4340\n",
      "Epoch 10/60\n",
      "1402/1402 [==============================] - 1204s 859ms/step - loss: 1.1481 - rpn_class_loss: 0.0047 - rpn_bbox_loss: 0.2493 - mrcnn_class_loss: 0.1233 - mrcnn_bbox_loss: 0.3445 - mrcnn_mask_loss: 0.4262 - val_loss: 1.4088 - val_rpn_class_loss: 0.0053 - val_rpn_bbox_loss: 0.3991 - val_mrcnn_class_loss: 0.1484 - val_mrcnn_bbox_loss: 0.4075 - val_mrcnn_mask_loss: 0.4485\n",
      "Epoch 11/60\n",
      "1402/1402 [==============================] - 1204s 859ms/step - loss: 1.1534 - rpn_class_loss: 0.0049 - rpn_bbox_loss: 0.2621 - mrcnn_class_loss: 0.1235 - mrcnn_bbox_loss: 0.3379 - mrcnn_mask_loss: 0.4250 - val_loss: 1.4543 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.4193 - val_mrcnn_class_loss: 0.1809 - val_mrcnn_bbox_loss: 0.4151 - val_mrcnn_mask_loss: 0.4339\n",
      "Epoch 12/60\n",
      "1402/1402 [==============================] - 1202s 858ms/step - loss: 1.1027 - rpn_class_loss: 0.0047 - rpn_bbox_loss: 0.2440 - mrcnn_class_loss: 0.1289 - mrcnn_bbox_loss: 0.3147 - mrcnn_mask_loss: 0.4103 - val_loss: 1.4076 - val_rpn_class_loss: 0.0050 - val_rpn_bbox_loss: 0.4055 - val_mrcnn_class_loss: 0.1464 - val_mrcnn_bbox_loss: 0.4134 - val_mrcnn_mask_loss: 0.4373\n",
      "Epoch 13/60\n",
      "1402/1402 [==============================] - 1200s 856ms/step - loss: 1.0521 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.2134 - mrcnn_class_loss: 0.1279 - mrcnn_bbox_loss: 0.2990 - mrcnn_mask_loss: 0.4073 - val_loss: 1.5214 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.4368 - val_mrcnn_class_loss: 0.1539 - val_mrcnn_bbox_loss: 0.4288 - val_mrcnn_mask_loss: 0.4968\n",
      "Epoch 14/60\n",
      "1402/1402 [==============================] - 1201s 857ms/step - loss: 1.0494 - rpn_class_loss: 0.0043 - rpn_bbox_loss: 0.2037 - mrcnn_class_loss: 0.1362 - mrcnn_bbox_loss: 0.2933 - mrcnn_mask_loss: 0.4121 - val_loss: 1.4789 - val_rpn_class_loss: 0.0048 - val_rpn_bbox_loss: 0.5411 - val_mrcnn_class_loss: 0.1378 - val_mrcnn_bbox_loss: 0.3857 - val_mrcnn_mask_loss: 0.4095\n",
      "Epoch 15/60\n",
      "1402/1402 [==============================] - 1202s 857ms/step - loss: 1.0197 - rpn_class_loss: 0.0043 - rpn_bbox_loss: 0.2049 - mrcnn_class_loss: 0.1315 - mrcnn_bbox_loss: 0.2782 - mrcnn_mask_loss: 0.4008 - val_loss: 1.5212 - val_rpn_class_loss: 0.0047 - val_rpn_bbox_loss: 0.5297 - val_mrcnn_class_loss: 0.1458 - val_mrcnn_bbox_loss: 0.4141 - val_mrcnn_mask_loss: 0.4269\n",
      "Epoch 16/60\n",
      "1402/1402 [==============================] - 1201s 857ms/step - loss: 0.9661 - rpn_class_loss: 0.0041 - rpn_bbox_loss: 0.1685 - mrcnn_class_loss: 0.1305 - mrcnn_bbox_loss: 0.2645 - mrcnn_mask_loss: 0.3985 - val_loss: 1.5562 - val_rpn_class_loss: 0.0046 - val_rpn_bbox_loss: 0.5244 - val_mrcnn_class_loss: 0.1714 - val_mrcnn_bbox_loss: 0.4238 - val_mrcnn_mask_loss: 0.4319\n",
      "Epoch 17/60\n",
      "1402/1402 [==============================] - 1201s 857ms/step - loss: 0.9123 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.1452 - mrcnn_class_loss: 0.1283 - mrcnn_bbox_loss: 0.2432 - mrcnn_mask_loss: 0.3916 - val_loss: 1.8828 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.9199 - val_mrcnn_class_loss: 0.1218 - val_mrcnn_bbox_loss: 0.4017 - val_mrcnn_mask_loss: 0.4344\n",
      "Epoch 18/60\n",
      "1402/1402 [==============================] - 1201s 856ms/step - loss: 0.9037 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.1530 - mrcnn_class_loss: 0.1197 - mrcnn_bbox_loss: 0.2360 - mrcnn_mask_loss: 0.3913 - val_loss: 1.6137 - val_rpn_class_loss: 0.0047 - val_rpn_bbox_loss: 0.5963 - val_mrcnn_class_loss: 0.1655 - val_mrcnn_bbox_loss: 0.4257 - val_mrcnn_mask_loss: 0.4214\n",
      "Epoch 19/60\n",
      "1402/1402 [==============================] - 1201s 857ms/step - loss: 0.8492 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.1232 - mrcnn_class_loss: 0.1233 - mrcnn_bbox_loss: 0.2182 - mrcnn_mask_loss: 0.3807 - val_loss: 1.6516 - val_rpn_class_loss: 0.0048 - val_rpn_bbox_loss: 0.6371 - val_mrcnn_class_loss: 0.1468 - val_mrcnn_bbox_loss: 0.4213 - val_mrcnn_mask_loss: 0.4418\n",
      "Epoch 20/60\n",
      "1402/1402 [==============================] - 1201s 856ms/step - loss: 0.8143 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.1180 - mrcnn_class_loss: 0.1233 - mrcnn_bbox_loss: 0.2008 - mrcnn_mask_loss: 0.3685 - val_loss: 1.7130 - val_rpn_class_loss: 0.0047 - val_rpn_bbox_loss: 0.7079 - val_mrcnn_class_loss: 0.1524 - val_mrcnn_bbox_loss: 0.4098 - val_mrcnn_mask_loss: 0.4381\n",
      "Epoch 21/60\n",
      "1402/1402 [==============================] - 1204s 859ms/step - loss: 0.7913 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.1019 - mrcnn_class_loss: 0.1215 - mrcnn_bbox_loss: 0.1953 - mrcnn_mask_loss: 0.3690 - val_loss: 1.6556 - val_rpn_class_loss: 0.0050 - val_rpn_bbox_loss: 0.6655 - val_mrcnn_class_loss: 0.1397 - val_mrcnn_bbox_loss: 0.4130 - val_mrcnn_mask_loss: 0.4324\n",
      "Epoch 22/60\n",
      "1402/1402 [==============================] - 1205s 859ms/step - loss: 0.7507 - rpn_class_loss: 0.0033 - rpn_bbox_loss: 0.0991 - mrcnn_class_loss: 0.1173 - mrcnn_bbox_loss: 0.1779 - mrcnn_mask_loss: 0.3531 - val_loss: 1.6491 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.5743 - val_mrcnn_class_loss: 0.1807 - val_mrcnn_bbox_loss: 0.4279 - val_mrcnn_mask_loss: 0.4610\n",
      "Epoch 23/60\n",
      "1402/1402 [==============================] - 1202s 857ms/step - loss: 0.7531 - rpn_class_loss: 0.0033 - rpn_bbox_loss: 0.1031 - mrcnn_class_loss: 0.1122 - mrcnn_bbox_loss: 0.1760 - mrcnn_mask_loss: 0.3586 - val_loss: 1.6687 - val_rpn_class_loss: 0.0047 - val_rpn_bbox_loss: 0.6350 - val_mrcnn_class_loss: 0.1569 - val_mrcnn_bbox_loss: 0.4277 - val_mrcnn_mask_loss: 0.4444\n",
      "Epoch 24/60\n",
      "1402/1402 [==============================] - 1200s 856ms/step - loss: 0.7090 - rpn_class_loss: 0.0033 - rpn_bbox_loss: 0.0866 - mrcnn_class_loss: 0.1060 - mrcnn_bbox_loss: 0.1626 - mrcnn_mask_loss: 0.3504 - val_loss: 1.8395 - val_rpn_class_loss: 0.0049 - val_rpn_bbox_loss: 0.8296 - val_mrcnn_class_loss: 0.1394 - val_mrcnn_bbox_loss: 0.4200 - val_mrcnn_mask_loss: 0.4455\n",
      "Epoch 25/60\n",
      "1402/1402 [==============================] - 1202s 857ms/step - loss: 0.6678 - rpn_class_loss: 0.0031 - rpn_bbox_loss: 0.0793 - mrcnn_class_loss: 0.0990 - mrcnn_bbox_loss: 0.1472 - mrcnn_mask_loss: 0.3391 - val_loss: 1.7751 - val_rpn_class_loss: 0.0050 - val_rpn_bbox_loss: 0.6560 - val_mrcnn_class_loss: 0.2211 - val_mrcnn_bbox_loss: 0.4445 - val_mrcnn_mask_loss: 0.4485\n",
      "Epoch 26/60\n",
      "1402/1402 [==============================] - 1201s 856ms/step - loss: 0.6602 - rpn_class_loss: 0.0030 - rpn_bbox_loss: 0.0771 - mrcnn_class_loss: 0.0998 - mrcnn_bbox_loss: 0.1463 - mrcnn_mask_loss: 0.3339 - val_loss: 1.7412 - val_rpn_class_loss: 0.0050 - val_rpn_bbox_loss: 0.6452 - val_mrcnn_class_loss: 0.1858 - val_mrcnn_bbox_loss: 0.4356 - val_mrcnn_mask_loss: 0.4696\n",
      "Epoch 27/60\n",
      "1402/1402 [==============================] - 1203s 858ms/step - loss: 0.6242 - rpn_class_loss: 0.0029 - rpn_bbox_loss: 0.0714 - mrcnn_class_loss: 0.0944 - mrcnn_bbox_loss: 0.1346 - mrcnn_mask_loss: 0.3209 - val_loss: 1.7816 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.5659 - val_mrcnn_class_loss: 0.2297 - val_mrcnn_bbox_loss: 0.4613 - val_mrcnn_mask_loss: 0.5196\n",
      "Epoch 28/60\n",
      "1402/1402 [==============================] - 1224s 873ms/step - loss: 0.6223 - rpn_class_loss: 0.0029 - rpn_bbox_loss: 0.0678 - mrcnn_class_loss: 0.0937 - mrcnn_bbox_loss: 0.1329 - mrcnn_mask_loss: 0.3251 - val_loss: 1.7691 - val_rpn_class_loss: 0.0049 - val_rpn_bbox_loss: 0.6397 - val_mrcnn_class_loss: 0.2072 - val_mrcnn_bbox_loss: 0.4471 - val_mrcnn_mask_loss: 0.4702\n",
      "Epoch 29/60\n",
      "1402/1402 [==============================] - 1215s 867ms/step - loss: 0.6040 - rpn_class_loss: 0.0028 - rpn_bbox_loss: 0.0696 - mrcnn_class_loss: 0.0913 - mrcnn_bbox_loss: 0.1228 - mrcnn_mask_loss: 0.3174 - val_loss: 1.9777 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.6789 - val_mrcnn_class_loss: 0.2853 - val_mrcnn_bbox_loss: 0.4595 - val_mrcnn_mask_loss: 0.5489\n",
      "Epoch 30/60\n",
      "1402/1402 [==============================] - 1239s 884ms/step - loss: 0.5790 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0669 - mrcnn_class_loss: 0.0839 - mrcnn_bbox_loss: 0.1189 - mrcnn_mask_loss: 0.3067 - val_loss: 1.9619 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.8364 - val_mrcnn_class_loss: 0.2316 - val_mrcnn_bbox_loss: 0.4146 - val_mrcnn_mask_loss: 0.4742\n",
      "Epoch 31/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 1240s 884ms/step - loss: 0.5575 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0624 - mrcnn_class_loss: 0.0800 - mrcnn_bbox_loss: 0.1128 - mrcnn_mask_loss: 0.2995 - val_loss: 1.8726 - val_rpn_class_loss: 0.0050 - val_rpn_bbox_loss: 0.6627 - val_mrcnn_class_loss: 0.2723 - val_mrcnn_bbox_loss: 0.4478 - val_mrcnn_mask_loss: 0.4847\n",
      "Epoch 32/60\n",
      "1402/1402 [==============================] - 1238s 883ms/step - loss: 0.5432 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0599 - mrcnn_class_loss: 0.0761 - mrcnn_bbox_loss: 0.1064 - mrcnn_mask_loss: 0.2981 - val_loss: 1.8566 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.6110 - val_mrcnn_class_loss: 0.2753 - val_mrcnn_bbox_loss: 0.4495 - val_mrcnn_mask_loss: 0.5156\n",
      "Epoch 33/60\n",
      "1402/1402 [==============================] - 1241s 885ms/step - loss: 0.5213 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0557 - mrcnn_class_loss: 0.0707 - mrcnn_bbox_loss: 0.1038 - mrcnn_mask_loss: 0.2887 - val_loss: 2.0101 - val_rpn_class_loss: 0.0054 - val_rpn_bbox_loss: 0.7013 - val_mrcnn_class_loss: 0.3430 - val_mrcnn_bbox_loss: 0.4270 - val_mrcnn_mask_loss: 0.5333\n",
      "Epoch 34/60\n",
      "1402/1402 [==============================] - 1214s 866ms/step - loss: 0.5259 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0598 - mrcnn_class_loss: 0.0721 - mrcnn_bbox_loss: 0.1014 - mrcnn_mask_loss: 0.2901 - val_loss: 1.9851 - val_rpn_class_loss: 0.0052 - val_rpn_bbox_loss: 0.6971 - val_mrcnn_class_loss: 0.2634 - val_mrcnn_bbox_loss: 0.4545 - val_mrcnn_mask_loss: 0.5649\n",
      "Epoch 35/60\n",
      "1402/1402 [==============================] - 1211s 864ms/step - loss: 0.4982 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0539 - mrcnn_class_loss: 0.0679 - mrcnn_bbox_loss: 0.0925 - mrcnn_mask_loss: 0.2815 - val_loss: 2.0158 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.6106 - val_mrcnn_class_loss: 0.3890 - val_mrcnn_bbox_loss: 0.4645 - val_mrcnn_mask_loss: 0.5461\n",
      "Epoch 36/60\n",
      "1402/1402 [==============================] - 1200s 856ms/step - loss: 0.4804 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0480 - mrcnn_class_loss: 0.0681 - mrcnn_bbox_loss: 0.0906 - mrcnn_mask_loss: 0.2714 - val_loss: 2.1035 - val_rpn_class_loss: 0.0054 - val_rpn_bbox_loss: 0.7155 - val_mrcnn_class_loss: 0.3518 - val_mrcnn_bbox_loss: 0.4542 - val_mrcnn_mask_loss: 0.5766\n",
      "Epoch 37/60\n",
      "1402/1402 [==============================] - 1202s 857ms/step - loss: 0.4674 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0507 - mrcnn_class_loss: 0.0610 - mrcnn_bbox_loss: 0.0849 - mrcnn_mask_loss: 0.2684 - val_loss: 2.0782 - val_rpn_class_loss: 0.0055 - val_rpn_bbox_loss: 0.6431 - val_mrcnn_class_loss: 0.3955 - val_mrcnn_bbox_loss: 0.4634 - val_mrcnn_mask_loss: 0.5707\n",
      "Epoch 38/60\n",
      "1402/1402 [==============================] - 1201s 857ms/step - loss: 0.4558 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0454 - mrcnn_class_loss: 0.0580 - mrcnn_bbox_loss: 0.0853 - mrcnn_mask_loss: 0.2650 - val_loss: 2.0828 - val_rpn_class_loss: 0.0053 - val_rpn_bbox_loss: 0.6746 - val_mrcnn_class_loss: 0.3873 - val_mrcnn_bbox_loss: 0.4382 - val_mrcnn_mask_loss: 0.5775\n",
      "Epoch 39/60\n",
      "1402/1402 [==============================] - 1204s 859ms/step - loss: 0.4521 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0466 - mrcnn_class_loss: 0.0588 - mrcnn_bbox_loss: 0.0806 - mrcnn_mask_loss: 0.2639 - val_loss: 2.2287 - val_rpn_class_loss: 0.0056 - val_rpn_bbox_loss: 0.8097 - val_mrcnn_class_loss: 0.4190 - val_mrcnn_bbox_loss: 0.4353 - val_mrcnn_mask_loss: 0.5591\n",
      "Epoch 40/60\n",
      "1402/1402 [==============================] - 1205s 859ms/step - loss: 0.4360 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0485 - mrcnn_class_loss: 0.0556 - mrcnn_bbox_loss: 0.0761 - mrcnn_mask_loss: 0.2536 - val_loss: 2.1029 - val_rpn_class_loss: 0.0058 - val_rpn_bbox_loss: 0.7729 - val_mrcnn_class_loss: 0.3258 - val_mrcnn_bbox_loss: 0.4486 - val_mrcnn_mask_loss: 0.5498\n",
      "Epoch 41/60\n",
      "1402/1402 [==============================] - 1206s 860ms/step - loss: 0.4263 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0457 - mrcnn_class_loss: 0.0540 - mrcnn_bbox_loss: 0.0715 - mrcnn_mask_loss: 0.2529 - val_loss: 2.0220 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.5567 - val_mrcnn_class_loss: 0.3602 - val_mrcnn_bbox_loss: 0.4648 - val_mrcnn_mask_loss: 0.6346\n",
      "Epoch 42/60\n",
      "1402/1402 [==============================] - 1204s 859ms/step - loss: 0.4080 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0418 - mrcnn_class_loss: 0.0505 - mrcnn_bbox_loss: 0.0708 - mrcnn_mask_loss: 0.2430 - val_loss: 2.0863 - val_rpn_class_loss: 0.0054 - val_rpn_bbox_loss: 0.6829 - val_mrcnn_class_loss: 0.3527 - val_mrcnn_bbox_loss: 0.4342 - val_mrcnn_mask_loss: 0.6111\n",
      "Epoch 43/60\n",
      "1402/1402 [==============================] - 1203s 858ms/step - loss: 0.4033 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0386 - mrcnn_class_loss: 0.0522 - mrcnn_bbox_loss: 0.0693 - mrcnn_mask_loss: 0.2411 - val_loss: 2.2121 - val_rpn_class_loss: 0.0059 - val_rpn_bbox_loss: 0.6785 - val_mrcnn_class_loss: 0.4329 - val_mrcnn_bbox_loss: 0.4571 - val_mrcnn_mask_loss: 0.6377\n",
      "Epoch 44/60\n",
      "1402/1402 [==============================] - 1203s 858ms/step - loss: 0.3914 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0399 - mrcnn_class_loss: 0.0469 - mrcnn_bbox_loss: 0.0654 - mrcnn_mask_loss: 0.2372 - val_loss: 2.2359 - val_rpn_class_loss: 0.0060 - val_rpn_bbox_loss: 0.7801 - val_mrcnn_class_loss: 0.4547 - val_mrcnn_bbox_loss: 0.4372 - val_mrcnn_mask_loss: 0.5578\n",
      "Epoch 45/60\n",
      "1402/1402 [==============================] - 1204s 859ms/step - loss: 0.3803 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0372 - mrcnn_class_loss: 0.0457 - mrcnn_bbox_loss: 0.0637 - mrcnn_mask_loss: 0.2318 - val_loss: 2.1951 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.5946 - val_mrcnn_class_loss: 0.4857 - val_mrcnn_bbox_loss: 0.4632 - val_mrcnn_mask_loss: 0.6459\n",
      "Epoch 46/60\n",
      "1402/1402 [==============================] - 1203s 858ms/step - loss: 0.3721 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0375 - mrcnn_class_loss: 0.0429 - mrcnn_bbox_loss: 0.0623 - mrcnn_mask_loss: 0.2275 - val_loss: 2.3556 - val_rpn_class_loss: 0.0061 - val_rpn_bbox_loss: 0.7008 - val_mrcnn_class_loss: 0.5198 - val_mrcnn_bbox_loss: 0.4601 - val_mrcnn_mask_loss: 0.6688\n",
      "Epoch 47/60\n",
      "1402/1402 [==============================] - 1204s 859ms/step - loss: 0.3603 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0365 - mrcnn_class_loss: 0.0398 - mrcnn_bbox_loss: 0.0596 - mrcnn_mask_loss: 0.2228 - val_loss: 2.3105 - val_rpn_class_loss: 0.0062 - val_rpn_bbox_loss: 0.6359 - val_mrcnn_class_loss: 0.5296 - val_mrcnn_bbox_loss: 0.4512 - val_mrcnn_mask_loss: 0.6876\n",
      "Epoch 48/60\n",
      "1402/1402 [==============================] - 1201s 857ms/step - loss: 0.3562 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0388 - mrcnn_class_loss: 0.0393 - mrcnn_bbox_loss: 0.0583 - mrcnn_mask_loss: 0.2181 - val_loss: 2.5054 - val_rpn_class_loss: 0.0070 - val_rpn_bbox_loss: 0.5772 - val_mrcnn_class_loss: 0.5841 - val_mrcnn_bbox_loss: 0.4759 - val_mrcnn_mask_loss: 0.8611\n",
      "Epoch 49/60\n",
      "1402/1402 [==============================] - 1201s 857ms/step - loss: 0.3548 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0347 - mrcnn_class_loss: 0.0395 - mrcnn_bbox_loss: 0.0575 - mrcnn_mask_loss: 0.2213 - val_loss: 2.3322 - val_rpn_class_loss: 0.0061 - val_rpn_bbox_loss: 0.6606 - val_mrcnn_class_loss: 0.4823 - val_mrcnn_bbox_loss: 0.4617 - val_mrcnn_mask_loss: 0.7214\n",
      "Epoch 50/60\n",
      "1402/1402 [==============================] - 1200s 856ms/step - loss: 0.3387 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0324 - mrcnn_class_loss: 0.0382 - mrcnn_bbox_loss: 0.0559 - mrcnn_mask_loss: 0.2106 - val_loss: 2.4485 - val_rpn_class_loss: 0.0063 - val_rpn_bbox_loss: 0.6095 - val_mrcnn_class_loss: 0.5813 - val_mrcnn_bbox_loss: 0.4711 - val_mrcnn_mask_loss: 0.7802\n",
      "Epoch 51/60\n",
      "1402/1402 [==============================] - 1204s 859ms/step - loss: 0.3293 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0324 - mrcnn_class_loss: 0.0382 - mrcnn_bbox_loss: 0.0508 - mrcnn_mask_loss: 0.2061 - val_loss: 2.4499 - val_rpn_class_loss: 0.0062 - val_rpn_bbox_loss: 0.7174 - val_mrcnn_class_loss: 0.5647 - val_mrcnn_bbox_loss: 0.4500 - val_mrcnn_mask_loss: 0.7117\n",
      "Epoch 52/60\n",
      "1402/1402 [==============================] - 1202s 857ms/step - loss: 0.3309 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0319 - mrcnn_class_loss: 0.0359 - mrcnn_bbox_loss: 0.0531 - mrcnn_mask_loss: 0.2084 - val_loss: 2.2836 - val_rpn_class_loss: 0.0060 - val_rpn_bbox_loss: 0.6461 - val_mrcnn_class_loss: 0.4846 - val_mrcnn_bbox_loss: 0.4607 - val_mrcnn_mask_loss: 0.6863\n",
      "Epoch 53/60\n",
      "1402/1402 [==============================] - 1219s 869ms/step - loss: 0.3238 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0308 - mrcnn_class_loss: 0.0369 - mrcnn_bbox_loss: 0.0506 - mrcnn_mask_loss: 0.2040 - val_loss: 2.4876 - val_rpn_class_loss: 0.0069 - val_rpn_bbox_loss: 0.6380 - val_mrcnn_class_loss: 0.5668 - val_mrcnn_bbox_loss: 0.4610 - val_mrcnn_mask_loss: 0.8149\n",
      "Epoch 54/60\n",
      "1402/1402 [==============================] - 1219s 870ms/step - loss: 0.3138 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0285 - mrcnn_class_loss: 0.0364 - mrcnn_bbox_loss: 0.0481 - mrcnn_mask_loss: 0.1994 - val_loss: 2.3992 - val_rpn_class_loss: 0.0063 - val_rpn_bbox_loss: 0.7405 - val_mrcnn_class_loss: 0.5182 - val_mrcnn_bbox_loss: 0.4339 - val_mrcnn_mask_loss: 0.7004\n",
      "Epoch 55/60\n",
      "1402/1402 [==============================] - 1220s 871ms/step - loss: 0.3141 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0317 - mrcnn_class_loss: 0.0322 - mrcnn_bbox_loss: 0.0489 - mrcnn_mask_loss: 0.1998 - val_loss: 2.4483 - val_rpn_class_loss: 0.0061 - val_rpn_bbox_loss: 0.7773 - val_mrcnn_class_loss: 0.5288 - val_mrcnn_bbox_loss: 0.4310 - val_mrcnn_mask_loss: 0.7051\n",
      "Epoch 56/60\n",
      "1402/1402 [==============================] - 1226s 874ms/step - loss: 0.3020 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0317 - mrcnn_class_loss: 0.0324 - mrcnn_bbox_loss: 0.0448 - mrcnn_mask_loss: 0.1917 - val_loss: 2.4632 - val_rpn_class_loss: 0.0069 - val_rpn_bbox_loss: 0.6149 - val_mrcnn_class_loss: 0.6275 - val_mrcnn_bbox_loss: 0.4601 - val_mrcnn_mask_loss: 0.7538\n",
      "Epoch 57/60\n",
      "1402/1402 [==============================] - 1240s 885ms/step - loss: 0.2989 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0283 - mrcnn_class_loss: 0.0314 - mrcnn_bbox_loss: 0.0457 - mrcnn_mask_loss: 0.1921 - val_loss: 2.5878 - val_rpn_class_loss: 0.0071 - val_rpn_bbox_loss: 0.6923 - val_mrcnn_class_loss: 0.5935 - val_mrcnn_bbox_loss: 0.4369 - val_mrcnn_mask_loss: 0.8579\n",
      "Epoch 58/60\n",
      "1402/1402 [==============================] - 1239s 884ms/step - loss: 0.2978 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0279 - mrcnn_class_loss: 0.0330 - mrcnn_bbox_loss: 0.0450 - mrcnn_mask_loss: 0.1905 - val_loss: 2.5288 - val_rpn_class_loss: 0.0065 - val_rpn_bbox_loss: 0.6303 - val_mrcnn_class_loss: 0.6409 - val_mrcnn_bbox_loss: 0.4681 - val_mrcnn_mask_loss: 0.7829\n",
      "Epoch 59/60\n",
      "1402/1402 [==============================] - 1241s 885ms/step - loss: 0.2802 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0271 - mrcnn_class_loss: 0.0285 - mrcnn_bbox_loss: 0.0406 - mrcnn_mask_loss: 0.1827 - val_loss: 2.7188 - val_rpn_class_loss: 0.0072 - val_rpn_bbox_loss: 0.7793 - val_mrcnn_class_loss: 0.6173 - val_mrcnn_bbox_loss: 0.4406 - val_mrcnn_mask_loss: 0.8744\n",
      "Epoch 60/60\n",
      "1402/1402 [==============================] - 1242s 886ms/step - loss: 0.2859 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0281 - mrcnn_class_loss: 0.0308 - mrcnn_bbox_loss: 0.0421 - mrcnn_mask_loss: 0.1835 - val_loss: 2.6835 - val_rpn_class_loss: 0.0071 - val_rpn_bbox_loss: 0.5348 - val_mrcnn_class_loss: 0.7303 - val_mrcnn_bbox_loss: 0.4625 - val_mrcnn_mask_loss: 0.9487\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "# Use configuation from mammo.py, but override\n",
    "# image resizing so we see the real sizes here\n",
    "class NoResizeConfig(mammo.MammoConfig):\n",
    "#     IMAGE_RESIZE_MODE = \"none\"\n",
    "#     USE_MINI_MASK = False\n",
    "    # Adjust depending on your GPU memory\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + mass\n",
    "\n",
    "    # Number of training and validation steps per epoch\n",
    "    STEPS_PER_EPOCH = (len(dataset_train.image_ids) - len(dataset_val.image_ids)) // IMAGES_PER_GPU\n",
    "    VALIDATION_STEPS = max(1, len(dataset_val.image_ids) // IMAGES_PER_GPU)\n",
    "    \n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 512\n",
    "    \n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 1000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "    \n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "    \n",
    "config = NoResizeConfig()\n",
    "config.display()\n",
    "\n",
    "MODEL_DIR = 'checkpoints'\n",
    "\n",
    "# Create model\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,                          \n",
    "                          model_dir=MODEL_DIR)\n",
    "# Select weights file to load\n",
    "weights_path = model.get_imagenet_weights()\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "model.train(dataset_train, dataset_val, config.LEARNING_RATE, epochs=60, layers='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train #3\n",
    "### With 2000 POST_NMS_ROIS_TRAINING and 2500 POST_NMS_ROIS_INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [54.78 54.78 54.78]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           mammo\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2500\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (16, 32, 64, 128, 256)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.9\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    512\n",
      "STEPS_PER_EPOCH                984\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               245\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  C:\\Users\\Chevy\\AppData\\Local\\Temp\\.keras\\models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: checkpoints\\mammo20180716T2155\\mask_rcnn_mammo_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chevy\\Anaconda3\\envs\\nnets\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/60\n",
      "984/984 [==============================] - 1193s 1s/step - loss: 1.0901 - rpn_class_loss: 0.0338 - rpn_bbox_loss: 0.5069 - mrcnn_class_loss: 0.0181 - mrcnn_bbox_loss: 0.2672 - mrcnn_mask_loss: 0.2641 - val_loss: 1.0359 - val_rpn_class_loss: 0.0123 - val_rpn_bbox_loss: 0.3894 - val_mrcnn_class_loss: 0.0185 - val_mrcnn_bbox_loss: 0.2825 - val_mrcnn_mask_loss: 0.3332\n",
      "Epoch 2/60\n",
      "984/984 [==============================] - 1172s 1s/step - loss: 1.2185 - rpn_class_loss: 0.0103 - rpn_bbox_loss: 0.3627 - mrcnn_class_loss: 0.0455 - mrcnn_bbox_loss: 0.3426 - mrcnn_mask_loss: 0.4575 - val_loss: 1.1466 - val_rpn_class_loss: 0.0087 - val_rpn_bbox_loss: 0.4233 - val_mrcnn_class_loss: 0.0376 - val_mrcnn_bbox_loss: 0.3067 - val_mrcnn_mask_loss: 0.3702\n",
      "Epoch 3/60\n",
      "984/984 [==============================] - 1175s 1s/step - loss: 1.1447 - rpn_class_loss: 0.0075 - rpn_bbox_loss: 0.3120 - mrcnn_class_loss: 0.0620 - mrcnn_bbox_loss: 0.3380 - mrcnn_mask_loss: 0.4251 - val_loss: 1.2310 - val_rpn_class_loss: 0.0063 - val_rpn_bbox_loss: 0.3277 - val_mrcnn_class_loss: 0.0908 - val_mrcnn_bbox_loss: 0.3739 - val_mrcnn_mask_loss: 0.4323\n",
      "Epoch 4/60\n",
      "984/984 [==============================] - 1178s 1s/step - loss: 1.1141 - rpn_class_loss: 0.0061 - rpn_bbox_loss: 0.2832 - mrcnn_class_loss: 0.0856 - mrcnn_bbox_loss: 0.3280 - mrcnn_mask_loss: 0.4112 - val_loss: 1.2031 - val_rpn_class_loss: 0.0052 - val_rpn_bbox_loss: 0.3868 - val_mrcnn_class_loss: 0.0870 - val_mrcnn_bbox_loss: 0.3379 - val_mrcnn_mask_loss: 0.3863\n",
      "Epoch 5/60\n",
      "984/984 [==============================] - 1179s 1s/step - loss: 1.0967 - rpn_class_loss: 0.0049 - rpn_bbox_loss: 0.2537 - mrcnn_class_loss: 0.1098 - mrcnn_bbox_loss: 0.3172 - mrcnn_mask_loss: 0.4111 - val_loss: 1.1560 - val_rpn_class_loss: 0.0049 - val_rpn_bbox_loss: 0.2840 - val_mrcnn_class_loss: 0.1268 - val_mrcnn_bbox_loss: 0.3385 - val_mrcnn_mask_loss: 0.4018\n",
      "Epoch 6/60\n",
      "984/984 [==============================] - 1177s 1s/step - loss: 1.0349 - rpn_class_loss: 0.0043 - rpn_bbox_loss: 0.2327 - mrcnn_class_loss: 0.1139 - mrcnn_bbox_loss: 0.2903 - mrcnn_mask_loss: 0.3937 - val_loss: 1.1847 - val_rpn_class_loss: 0.0040 - val_rpn_bbox_loss: 0.2880 - val_mrcnn_class_loss: 0.1514 - val_mrcnn_bbox_loss: 0.3414 - val_mrcnn_mask_loss: 0.3999\n",
      "Epoch 7/60\n",
      "984/984 [==============================] - 1172s 1s/step - loss: 0.9874 - rpn_class_loss: 0.0040 - rpn_bbox_loss: 0.2114 - mrcnn_class_loss: 0.1175 - mrcnn_bbox_loss: 0.2729 - mrcnn_mask_loss: 0.3817 - val_loss: 1.1693 - val_rpn_class_loss: 0.0035 - val_rpn_bbox_loss: 0.2909 - val_mrcnn_class_loss: 0.1537 - val_mrcnn_bbox_loss: 0.3254 - val_mrcnn_mask_loss: 0.3958\n",
      "Epoch 8/60\n",
      "984/984 [==============================] - 1175s 1s/step - loss: 0.9465 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.1832 - mrcnn_class_loss: 0.1323 - mrcnn_bbox_loss: 0.2499 - mrcnn_mask_loss: 0.3777 - val_loss: 1.1362 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.2967 - val_mrcnn_class_loss: 0.1370 - val_mrcnn_bbox_loss: 0.3217 - val_mrcnn_mask_loss: 0.3774\n",
      "Epoch 9/60\n",
      "984/984 [==============================] - 1174s 1s/step - loss: 0.8801 - rpn_class_loss: 0.0031 - rpn_bbox_loss: 0.1553 - mrcnn_class_loss: 0.1268 - mrcnn_bbox_loss: 0.2308 - mrcnn_mask_loss: 0.3641 - val_loss: 1.1108 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.2993 - val_mrcnn_class_loss: 0.1234 - val_mrcnn_bbox_loss: 0.3086 - val_mrcnn_mask_loss: 0.3763\n",
      "Epoch 10/60\n",
      "984/984 [==============================] - 1173s 1s/step - loss: 0.8276 - rpn_class_loss: 0.0030 - rpn_bbox_loss: 0.1348 - mrcnn_class_loss: 0.1293 - mrcnn_bbox_loss: 0.2088 - mrcnn_mask_loss: 0.3517 - val_loss: 1.1772 - val_rpn_class_loss: 0.0031 - val_rpn_bbox_loss: 0.3021 - val_mrcnn_class_loss: 0.1414 - val_mrcnn_bbox_loss: 0.3174 - val_mrcnn_mask_loss: 0.4132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/60\n",
      "984/984 [==============================] - 1173s 1s/step - loss: 0.7815 - rpn_class_loss: 0.0028 - rpn_bbox_loss: 0.1146 - mrcnn_class_loss: 0.1262 - mrcnn_bbox_loss: 0.1936 - mrcnn_mask_loss: 0.3443 - val_loss: 1.1722 - val_rpn_class_loss: 0.0031 - val_rpn_bbox_loss: 0.3903 - val_mrcnn_class_loss: 0.1228 - val_mrcnn_bbox_loss: 0.2902 - val_mrcnn_mask_loss: 0.3658\n",
      "Epoch 12/60\n",
      "984/984 [==============================] - 1177s 1s/step - loss: 0.7264 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0962 - mrcnn_class_loss: 0.1249 - mrcnn_bbox_loss: 0.1706 - mrcnn_mask_loss: 0.3321 - val_loss: 1.1936 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3595 - val_mrcnn_class_loss: 0.1290 - val_mrcnn_bbox_loss: 0.3180 - val_mrcnn_mask_loss: 0.3843\n",
      "Epoch 13/60\n",
      "984/984 [==============================] - 1178s 1s/step - loss: 0.6738 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0799 - mrcnn_class_loss: 0.1157 - mrcnn_bbox_loss: 0.1535 - mrcnn_mask_loss: 0.3223 - val_loss: 1.3115 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.2960 - val_mrcnn_class_loss: 0.2508 - val_mrcnn_bbox_loss: 0.3191 - val_mrcnn_mask_loss: 0.4430\n",
      "Epoch 14/60\n",
      "984/984 [==============================] - 1173s 1s/step - loss: 0.6490 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0823 - mrcnn_class_loss: 0.1118 - mrcnn_bbox_loss: 0.1390 - mrcnn_mask_loss: 0.3136 - val_loss: 1.2501 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3554 - val_mrcnn_class_loss: 0.1621 - val_mrcnn_bbox_loss: 0.3197 - val_mrcnn_mask_loss: 0.4103\n",
      "Epoch 15/60\n",
      "984/984 [==============================] - 1174s 1s/step - loss: 0.5881 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0659 - mrcnn_class_loss: 0.0996 - mrcnn_bbox_loss: 0.1240 - mrcnn_mask_loss: 0.2965 - val_loss: 1.2927 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3486 - val_mrcnn_class_loss: 0.2026 - val_mrcnn_bbox_loss: 0.3132 - val_mrcnn_mask_loss: 0.4256\n",
      "Epoch 16/60\n",
      "984/984 [==============================] - 1176s 1s/step - loss: 0.5576 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0589 - mrcnn_class_loss: 0.0984 - mrcnn_bbox_loss: 0.1121 - mrcnn_mask_loss: 0.2861 - val_loss: 1.3925 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3422 - val_mrcnn_class_loss: 0.3258 - val_mrcnn_bbox_loss: 0.3102 - val_mrcnn_mask_loss: 0.4115\n",
      "Epoch 17/60\n",
      "984/984 [==============================] - 1175s 1s/step - loss: 0.5228 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0544 - mrcnn_class_loss: 0.0890 - mrcnn_bbox_loss: 0.0997 - mrcnn_mask_loss: 0.2778 - val_loss: 1.4349 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3003 - val_mrcnn_class_loss: 0.3066 - val_mrcnn_bbox_loss: 0.3401 - val_mrcnn_mask_loss: 0.4852\n",
      "Epoch 18/60\n",
      "984/984 [==============================] - 1174s 1s/step - loss: 0.4885 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0499 - mrcnn_class_loss: 0.0817 - mrcnn_bbox_loss: 0.0899 - mrcnn_mask_loss: 0.2652 - val_loss: 1.4098 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3341 - val_mrcnn_class_loss: 0.3070 - val_mrcnn_bbox_loss: 0.3184 - val_mrcnn_mask_loss: 0.4478\n",
      "Epoch 19/60\n",
      "984/984 [==============================] - 1177s 1s/step - loss: 0.4665 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0489 - mrcnn_class_loss: 0.0763 - mrcnn_bbox_loss: 0.0835 - mrcnn_mask_loss: 0.2561 - val_loss: 1.5120 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3239 - val_mrcnn_class_loss: 0.3821 - val_mrcnn_bbox_loss: 0.3314 - val_mrcnn_mask_loss: 0.4719\n",
      "Epoch 20/60\n",
      "984/984 [==============================] - 1177s 1s/step - loss: 0.4413 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0459 - mrcnn_class_loss: 0.0705 - mrcnn_bbox_loss: 0.0762 - mrcnn_mask_loss: 0.2471 - val_loss: 1.6532 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3067 - val_mrcnn_class_loss: 0.4089 - val_mrcnn_bbox_loss: 0.3405 - val_mrcnn_mask_loss: 0.5943\n",
      "Epoch 21/60\n",
      "984/984 [==============================] - 1175s 1s/step - loss: 0.4156 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0421 - mrcnn_class_loss: 0.0618 - mrcnn_bbox_loss: 0.0695 - mrcnn_mask_loss: 0.2406 - val_loss: 1.6276 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3350 - val_mrcnn_class_loss: 0.4439 - val_mrcnn_bbox_loss: 0.3384 - val_mrcnn_mask_loss: 0.5073\n",
      "Epoch 22/60\n",
      "984/984 [==============================] - 1176s 1s/step - loss: 0.4043 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0383 - mrcnn_class_loss: 0.0652 - mrcnn_bbox_loss: 0.0664 - mrcnn_mask_loss: 0.2328 - val_loss: 1.8048 - val_rpn_class_loss: 0.0030 - val_rpn_bbox_loss: 0.3481 - val_mrcnn_class_loss: 0.5204 - val_mrcnn_bbox_loss: 0.3428 - val_mrcnn_mask_loss: 0.5904\n",
      "Epoch 23/60\n",
      "984/984 [==============================] - 1175s 1s/step - loss: 0.3886 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0367 - mrcnn_class_loss: 0.0629 - mrcnn_bbox_loss: 0.0612 - mrcnn_mask_loss: 0.2264 - val_loss: 1.6757 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3283 - val_mrcnn_class_loss: 0.4206 - val_mrcnn_bbox_loss: 0.3366 - val_mrcnn_mask_loss: 0.5878\n",
      "Epoch 24/60\n",
      "984/984 [==============================] - 1175s 1s/step - loss: 0.3707 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0363 - mrcnn_class_loss: 0.0596 - mrcnn_bbox_loss: 0.0560 - mrcnn_mask_loss: 0.2175 - val_loss: 1.8325 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3249 - val_mrcnn_class_loss: 0.5440 - val_mrcnn_bbox_loss: 0.3644 - val_mrcnn_mask_loss: 0.5964\n",
      "Epoch 25/60\n",
      "984/984 [==============================] - 1176s 1s/step - loss: 0.3528 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0335 - mrcnn_class_loss: 0.0521 - mrcnn_bbox_loss: 0.0538 - mrcnn_mask_loss: 0.2120 - val_loss: 1.6887 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3405 - val_mrcnn_class_loss: 0.4481 - val_mrcnn_bbox_loss: 0.3328 - val_mrcnn_mask_loss: 0.5647\n",
      "Epoch 26/60\n",
      "984/984 [==============================] - 1178s 1s/step - loss: 0.3511 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0349 - mrcnn_class_loss: 0.0530 - mrcnn_bbox_loss: 0.0516 - mrcnn_mask_loss: 0.2104 - val_loss: 1.8573 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3142 - val_mrcnn_class_loss: 0.5174 - val_mrcnn_bbox_loss: 0.3448 - val_mrcnn_mask_loss: 0.6781\n",
      "Epoch 27/60\n",
      "984/984 [==============================] - 1177s 1s/step - loss: 0.3311 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0317 - mrcnn_class_loss: 0.0492 - mrcnn_bbox_loss: 0.0485 - mrcnn_mask_loss: 0.2006 - val_loss: 1.9975 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3233 - val_mrcnn_class_loss: 0.5924 - val_mrcnn_bbox_loss: 0.3373 - val_mrcnn_mask_loss: 0.7418\n",
      "Epoch 28/60\n",
      "984/984 [==============================] - 1178s 1s/step - loss: 0.3211 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0300 - mrcnn_class_loss: 0.0477 - mrcnn_bbox_loss: 0.0466 - mrcnn_mask_loss: 0.1958 - val_loss: 1.8556 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3291 - val_mrcnn_class_loss: 0.5560 - val_mrcnn_bbox_loss: 0.3506 - val_mrcnn_mask_loss: 0.6170\n",
      "Epoch 29/60\n",
      "984/984 [==============================] - 1179s 1s/step - loss: 0.3118 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0300 - mrcnn_class_loss: 0.0437 - mrcnn_bbox_loss: 0.0440 - mrcnn_mask_loss: 0.1931 - val_loss: 1.8424 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3195 - val_mrcnn_class_loss: 0.5583 - val_mrcnn_bbox_loss: 0.3320 - val_mrcnn_mask_loss: 0.6297\n",
      "Epoch 30/60\n",
      "984/984 [==============================] - 1180s 1s/step - loss: 0.3008 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0290 - mrcnn_class_loss: 0.0420 - mrcnn_bbox_loss: 0.0412 - mrcnn_mask_loss: 0.1875 - val_loss: 1.9495 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3213 - val_mrcnn_class_loss: 0.6114 - val_mrcnn_bbox_loss: 0.3415 - val_mrcnn_mask_loss: 0.6725\n",
      "Epoch 31/60\n",
      "984/984 [==============================] - 1178s 1s/step - loss: 0.2981 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0277 - mrcnn_class_loss: 0.0429 - mrcnn_bbox_loss: 0.0398 - mrcnn_mask_loss: 0.1866 - val_loss: 1.9591 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.2937 - val_mrcnn_class_loss: 0.6732 - val_mrcnn_bbox_loss: 0.3546 - val_mrcnn_mask_loss: 0.6351\n",
      "Epoch 32/60\n",
      "984/984 [==============================] - 1178s 1s/step - loss: 0.2869 - rpn_class_loss: 9.7783e-04 - rpn_bbox_loss: 0.0288 - mrcnn_class_loss: 0.0372 - mrcnn_bbox_loss: 0.0390 - mrcnn_mask_loss: 0.1809 - val_loss: 1.9369 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3368 - val_mrcnn_class_loss: 0.5584 - val_mrcnn_bbox_loss: 0.3407 - val_mrcnn_mask_loss: 0.6985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/60\n",
      "984/984 [==============================] - 1178s 1s/step - loss: 0.2788 - rpn_class_loss: 9.7027e-04 - rpn_bbox_loss: 0.0257 - mrcnn_class_loss: 0.0380 - mrcnn_bbox_loss: 0.0361 - mrcnn_mask_loss: 0.1780 - val_loss: 2.0119 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3080 - val_mrcnn_class_loss: 0.6276 - val_mrcnn_bbox_loss: 0.3551 - val_mrcnn_mask_loss: 0.7187\n",
      "Epoch 34/60\n",
      "984/984 [==============================] - 1176s 1s/step - loss: 0.2730 - rpn_class_loss: 9.1119e-04 - rpn_bbox_loss: 0.0252 - mrcnn_class_loss: 0.0376 - mrcnn_bbox_loss: 0.0357 - mrcnn_mask_loss: 0.1735 - val_loss: 2.1726 - val_rpn_class_loss: 0.0030 - val_rpn_bbox_loss: 0.3216 - val_mrcnn_class_loss: 0.7483 - val_mrcnn_bbox_loss: 0.3666 - val_mrcnn_mask_loss: 0.7331\n",
      "Epoch 35/60\n",
      "984/984 [==============================] - 1177s 1s/step - loss: 0.2653 - rpn_class_loss: 9.1526e-04 - rpn_bbox_loss: 0.0260 - mrcnn_class_loss: 0.0347 - mrcnn_bbox_loss: 0.0343 - mrcnn_mask_loss: 0.1694 - val_loss: 2.3798 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.3082 - val_mrcnn_class_loss: 0.8000 - val_mrcnn_bbox_loss: 0.3620 - val_mrcnn_mask_loss: 0.9061\n",
      "Epoch 36/60\n",
      "984/984 [==============================] - 1180s 1s/step - loss: 0.2641 - rpn_class_loss: 9.2457e-04 - rpn_bbox_loss: 0.0245 - mrcnn_class_loss: 0.0347 - mrcnn_bbox_loss: 0.0342 - mrcnn_mask_loss: 0.1698 - val_loss: 2.1424 - val_rpn_class_loss: 0.0031 - val_rpn_bbox_loss: 0.3243 - val_mrcnn_class_loss: 0.7867 - val_mrcnn_bbox_loss: 0.3373 - val_mrcnn_mask_loss: 0.6910\n",
      "Epoch 37/60\n",
      "984/984 [==============================] - 1180s 1s/step - loss: 0.2534 - rpn_class_loss: 8.5636e-04 - rpn_bbox_loss: 0.0240 - mrcnn_class_loss: 0.0326 - mrcnn_bbox_loss: 0.0318 - mrcnn_mask_loss: 0.1641 - val_loss: 2.2348 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3174 - val_mrcnn_class_loss: 0.7264 - val_mrcnn_bbox_loss: 0.3532 - val_mrcnn_mask_loss: 0.8350\n",
      "Epoch 38/60\n",
      "984/984 [==============================] - 1178s 1s/step - loss: 0.2488 - rpn_class_loss: 8.1473e-04 - rpn_bbox_loss: 0.0232 - mrcnn_class_loss: 0.0332 - mrcnn_bbox_loss: 0.0310 - mrcnn_mask_loss: 0.1606 - val_loss: 2.1036 - val_rpn_class_loss: 0.0030 - val_rpn_bbox_loss: 0.3700 - val_mrcnn_class_loss: 0.5863 - val_mrcnn_bbox_loss: 0.3479 - val_mrcnn_mask_loss: 0.7963\n",
      "Epoch 39/60\n",
      "984/984 [==============================] - 1179s 1s/step - loss: 0.2404 - rpn_class_loss: 8.4761e-04 - rpn_bbox_loss: 0.0222 - mrcnn_class_loss: 0.0320 - mrcnn_bbox_loss: 0.0287 - mrcnn_mask_loss: 0.1567 - val_loss: 1.8819 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.3172 - val_mrcnn_class_loss: 0.5789 - val_mrcnn_bbox_loss: 0.3374 - val_mrcnn_mask_loss: 0.6460\n",
      "Epoch 40/60\n",
      "984/984 [==============================] - 1179s 1s/step - loss: 0.2321 - rpn_class_loss: 8.1604e-04 - rpn_bbox_loss: 0.0221 - mrcnn_class_loss: 0.0291 - mrcnn_bbox_loss: 0.0278 - mrcnn_mask_loss: 0.1522 - val_loss: 1.9329 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.3465 - val_mrcnn_class_loss: 0.5971 - val_mrcnn_bbox_loss: 0.3154 - val_mrcnn_mask_loss: 0.6706\n",
      "Epoch 41/60\n",
      "984/984 [==============================] - 1182s 1s/step - loss: 0.2332 - rpn_class_loss: 7.9253e-04 - rpn_bbox_loss: 0.0204 - mrcnn_class_loss: 0.0316 - mrcnn_bbox_loss: 0.0279 - mrcnn_mask_loss: 0.1525 - val_loss: 2.0085 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3227 - val_mrcnn_class_loss: 0.6497 - val_mrcnn_bbox_loss: 0.3438 - val_mrcnn_mask_loss: 0.6893\n",
      "Epoch 42/60\n",
      "984/984 [==============================] - 1187s 1s/step - loss: 0.2238 - rpn_class_loss: 7.6091e-04 - rpn_bbox_loss: 0.0209 - mrcnn_class_loss: 0.0284 - mrcnn_bbox_loss: 0.0260 - mrcnn_mask_loss: 0.1477 - val_loss: 1.9580 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3257 - val_mrcnn_class_loss: 0.6641 - val_mrcnn_bbox_loss: 0.3404 - val_mrcnn_mask_loss: 0.6251\n",
      "Epoch 43/60\n",
      "984/984 [==============================] - 1179s 1s/step - loss: 0.2166 - rpn_class_loss: 7.3114e-04 - rpn_bbox_loss: 0.0192 - mrcnn_class_loss: 0.0263 - mrcnn_bbox_loss: 0.0247 - mrcnn_mask_loss: 0.1456 - val_loss: 2.3341 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.3541 - val_mrcnn_class_loss: 0.8276 - val_mrcnn_bbox_loss: 0.3322 - val_mrcnn_mask_loss: 0.8170\n",
      "Epoch 44/60\n",
      "984/984 [==============================] - 1180s 1s/step - loss: 0.2126 - rpn_class_loss: 6.9949e-04 - rpn_bbox_loss: 0.0192 - mrcnn_class_loss: 0.0253 - mrcnn_bbox_loss: 0.0241 - mrcnn_mask_loss: 0.1433 - val_loss: 2.4999 - val_rpn_class_loss: 0.0035 - val_rpn_bbox_loss: 0.2975 - val_mrcnn_class_loss: 0.8514 - val_mrcnn_bbox_loss: 0.3592 - val_mrcnn_mask_loss: 0.9883\n",
      "Epoch 45/60\n",
      "984/984 [==============================] - 1180s 1s/step - loss: 0.2117 - rpn_class_loss: 6.8912e-04 - rpn_bbox_loss: 0.0185 - mrcnn_class_loss: 0.0268 - mrcnn_bbox_loss: 0.0242 - mrcnn_mask_loss: 0.1414 - val_loss: 2.4582 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.3099 - val_mrcnn_class_loss: 0.9296 - val_mrcnn_bbox_loss: 0.3504 - val_mrcnn_mask_loss: 0.8652\n",
      "Epoch 46/60\n",
      "984/984 [==============================] - 1178s 1s/step - loss: 0.2061 - rpn_class_loss: 6.3819e-04 - rpn_bbox_loss: 0.0173 - mrcnn_class_loss: 0.0254 - mrcnn_bbox_loss: 0.0231 - mrcnn_mask_loss: 0.1397 - val_loss: 2.4692 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3307 - val_mrcnn_class_loss: 1.0051 - val_mrcnn_bbox_loss: 0.3425 - val_mrcnn_mask_loss: 0.7880\n",
      "Epoch 47/60\n",
      "984/984 [==============================] - 1178s 1s/step - loss: 0.2022 - rpn_class_loss: 6.3487e-04 - rpn_bbox_loss: 0.0184 - mrcnn_class_loss: 0.0225 - mrcnn_bbox_loss: 0.0221 - mrcnn_mask_loss: 0.1385 - val_loss: 2.5246 - val_rpn_class_loss: 0.0034 - val_rpn_bbox_loss: 0.3340 - val_mrcnn_class_loss: 0.9796 - val_mrcnn_bbox_loss: 0.3393 - val_mrcnn_mask_loss: 0.8683\n",
      "Epoch 48/60\n",
      "984/984 [==============================] - 1180s 1s/step - loss: 0.1968 - rpn_class_loss: 6.1467e-04 - rpn_bbox_loss: 0.0165 - mrcnn_class_loss: 0.0238 - mrcnn_bbox_loss: 0.0211 - mrcnn_mask_loss: 0.1348 - val_loss: 2.2987 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.3168 - val_mrcnn_class_loss: 0.8209 - val_mrcnn_bbox_loss: 0.3341 - val_mrcnn_mask_loss: 0.8237\n",
      "Epoch 49/60\n",
      "984/984 [==============================] - 1178s 1s/step - loss: 0.1937 - rpn_class_loss: 6.2553e-04 - rpn_bbox_loss: 0.0167 - mrcnn_class_loss: 0.0237 - mrcnn_bbox_loss: 0.0214 - mrcnn_mask_loss: 0.1313 - val_loss: 2.5219 - val_rpn_class_loss: 0.0035 - val_rpn_bbox_loss: 0.3283 - val_mrcnn_class_loss: 0.9982 - val_mrcnn_bbox_loss: 0.3498 - val_mrcnn_mask_loss: 0.8421\n",
      "Epoch 50/60\n",
      "984/984 [==============================] - 1179s 1s/step - loss: 0.1902 - rpn_class_loss: 6.3801e-04 - rpn_bbox_loss: 0.0154 - mrcnn_class_loss: 0.0237 - mrcnn_bbox_loss: 0.0203 - mrcnn_mask_loss: 0.1301 - val_loss: 2.2721 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3450 - val_mrcnn_class_loss: 0.7976 - val_mrcnn_bbox_loss: 0.3294 - val_mrcnn_mask_loss: 0.7972\n",
      "Epoch 51/60\n",
      "984/984 [==============================] - 1180s 1s/step - loss: 0.1908 - rpn_class_loss: 6.0608e-04 - rpn_bbox_loss: 0.0162 - mrcnn_class_loss: 0.0241 - mrcnn_bbox_loss: 0.0204 - mrcnn_mask_loss: 0.1295 - val_loss: 2.2914 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.3107 - val_mrcnn_class_loss: 0.8775 - val_mrcnn_bbox_loss: 0.3385 - val_mrcnn_mask_loss: 0.7615\n",
      "Epoch 52/60\n",
      "984/984 [==============================] - 1181s 1s/step - loss: 0.1834 - rpn_class_loss: 5.9715e-04 - rpn_bbox_loss: 0.0161 - mrcnn_class_loss: 0.0215 - mrcnn_bbox_loss: 0.0189 - mrcnn_mask_loss: 0.1263 - val_loss: 2.3729 - val_rpn_class_loss: 0.0036 - val_rpn_bbox_loss: 0.3498 - val_mrcnn_class_loss: 0.8578 - val_mrcnn_bbox_loss: 0.3249 - val_mrcnn_mask_loss: 0.8368\n",
      "Epoch 53/60\n",
      "984/984 [==============================] - 1181s 1s/step - loss: 0.1897 - rpn_class_loss: 5.8303e-04 - rpn_bbox_loss: 0.0164 - mrcnn_class_loss: 0.0225 - mrcnn_bbox_loss: 0.0203 - mrcnn_mask_loss: 0.1299 - val_loss: 2.6727 - val_rpn_class_loss: 0.0037 - val_rpn_bbox_loss: 0.3116 - val_mrcnn_class_loss: 1.1775 - val_mrcnn_bbox_loss: 0.3434 - val_mrcnn_mask_loss: 0.8365\n",
      "Epoch 54/60\n",
      "984/984 [==============================] - 1182s 1s/step - loss: 0.1798 - rpn_class_loss: 5.4522e-04 - rpn_bbox_loss: 0.0143 - mrcnn_class_loss: 0.0221 - mrcnn_bbox_loss: 0.0186 - mrcnn_mask_loss: 0.1241 - val_loss: 2.4589 - val_rpn_class_loss: 0.0030 - val_rpn_bbox_loss: 0.3091 - val_mrcnn_class_loss: 1.0551 - val_mrcnn_bbox_loss: 0.3371 - val_mrcnn_mask_loss: 0.7546\n",
      "Epoch 55/60\n",
      "984/984 [==============================] - 1180s 1s/step - loss: 0.1762 - rpn_class_loss: 5.3329e-04 - rpn_bbox_loss: 0.0150 - mrcnn_class_loss: 0.0209 - mrcnn_bbox_loss: 0.0180 - mrcnn_mask_loss: 0.1218 - val_loss: 2.8937 - val_rpn_class_loss: 0.0037 - val_rpn_bbox_loss: 0.3054 - val_mrcnn_class_loss: 1.3224 - val_mrcnn_bbox_loss: 0.3503 - val_mrcnn_mask_loss: 0.9119\n",
      "Epoch 56/60\n",
      "984/984 [==============================] - 1180s 1s/step - loss: 0.1755 - rpn_class_loss: 5.2484e-04 - rpn_bbox_loss: 0.0148 - mrcnn_class_loss: 0.0217 - mrcnn_bbox_loss: 0.0180 - mrcnn_mask_loss: 0.1204 - val_loss: 2.4129 - val_rpn_class_loss: 0.0036 - val_rpn_bbox_loss: 0.3542 - val_mrcnn_class_loss: 0.9351 - val_mrcnn_bbox_loss: 0.3149 - val_mrcnn_mask_loss: 0.8051\n",
      "Epoch 57/60\n",
      "984/984 [==============================] - 1181s 1s/step - loss: 0.1691 - rpn_class_loss: 5.1175e-04 - rpn_bbox_loss: 0.0146 - mrcnn_class_loss: 0.0176 - mrcnn_bbox_loss: 0.0175 - mrcnn_mask_loss: 0.1189 - val_loss: 2.4246 - val_rpn_class_loss: 0.0034 - val_rpn_bbox_loss: 0.3574 - val_mrcnn_class_loss: 0.9378 - val_mrcnn_bbox_loss: 0.3376 - val_mrcnn_mask_loss: 0.7884\n",
      "Epoch 58/60\n",
      "984/984 [==============================] - 1182s 1s/step - loss: 0.1678 - rpn_class_loss: 4.9308e-04 - rpn_bbox_loss: 0.0139 - mrcnn_class_loss: 0.0203 - mrcnn_bbox_loss: 0.0166 - mrcnn_mask_loss: 0.1165 - val_loss: 2.6911 - val_rpn_class_loss: 0.0036 - val_rpn_bbox_loss: 0.3228 - val_mrcnn_class_loss: 1.0665 - val_mrcnn_bbox_loss: 0.3600 - val_mrcnn_mask_loss: 0.9381\n",
      "Epoch 59/60\n",
      "984/984 [==============================] - 1179s 1s/step - loss: 0.1663 - rpn_class_loss: 4.6676e-04 - rpn_bbox_loss: 0.0132 - mrcnn_class_loss: 0.0196 - mrcnn_bbox_loss: 0.0162 - mrcnn_mask_loss: 0.1168 - val_loss: 2.6391 - val_rpn_class_loss: 0.0034 - val_rpn_bbox_loss: 0.3110 - val_mrcnn_class_loss: 1.0788 - val_mrcnn_bbox_loss: 0.3499 - val_mrcnn_mask_loss: 0.8960\n",
      "Epoch 60/60\n",
      "984/984 [==============================] - 1183s 1s/step - loss: 0.1631 - rpn_class_loss: 4.6066e-04 - rpn_bbox_loss: 0.0122 - mrcnn_class_loss: 0.0191 - mrcnn_bbox_loss: 0.0163 - mrcnn_mask_loss: 0.1150 - val_loss: 2.2384 - val_rpn_class_loss: 0.0035 - val_rpn_bbox_loss: 0.3511 - val_mrcnn_class_loss: 0.7925 - val_mrcnn_bbox_loss: 0.3333 - val_mrcnn_mask_loss: 0.7580\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "# Use configuation from mammo.py, but override\n",
    "# image resizing so we see the real sizes here\n",
    "class NoResizeConfig(mammo.MammoConfig):\n",
    "#     IMAGE_RESIZE_MODE = \"none\"\n",
    "#     USE_MINI_MASK = False\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 512\n",
    "    \n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 2000\n",
    "    POST_NMS_ROIS_INFERENCE = 2500\n",
    "    \n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "    \n",
    "config = NoResizeConfig()\n",
    "config.display()\n",
    "\n",
    "MODEL_DIR = 'checkpoints'\n",
    "\n",
    "# Create model\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,                          \n",
    "                          model_dir=MODEL_DIR)\n",
    "# Select weights file to load\n",
    "weights_path = model.get_imagenet_weights()\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "model.train(dataset_train, dataset_val, config.LEARNING_RATE, epochs=60, layers='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training #2 \n",
    "### With proper bounding box and 60 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [54.78 54.78 54.78]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           mammo\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         1000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (16, 32, 64, 128, 256)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.9\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    512\n",
      "STEPS_PER_EPOCH                984\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               245\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  C:\\Users\\Chevy\\AppData\\Local\\Temp\\.keras\\models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: checkpoints\\mammo20180715T2144\\mask_rcnn_mammo_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chevy\\Anaconda3\\envs\\nnets\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/60\n",
      "984/984 [==============================] - 839s 853ms/step - loss: 1.1415 - rpn_class_loss: 0.0293 - rpn_bbox_loss: 0.5143 - mrcnn_class_loss: 0.0211 - mrcnn_bbox_loss: 0.2858 - mrcnn_mask_loss: 0.2908 - val_loss: 1.3159 - val_rpn_class_loss: 0.0094 - val_rpn_bbox_loss: 0.3789 - val_mrcnn_class_loss: 0.0466 - val_mrcnn_bbox_loss: 0.4167 - val_mrcnn_mask_loss: 0.4643\n",
      "Epoch 2/60\n",
      "984/984 [==============================] - 832s 845ms/step - loss: 1.1438 - rpn_class_loss: 0.0091 - rpn_bbox_loss: 0.3535 - mrcnn_class_loss: 0.0375 - mrcnn_bbox_loss: 0.3304 - mrcnn_mask_loss: 0.4133 - val_loss: 1.1271 - val_rpn_class_loss: 0.0081 - val_rpn_bbox_loss: 0.3352 - val_mrcnn_class_loss: 0.0482 - val_mrcnn_bbox_loss: 0.3356 - val_mrcnn_mask_loss: 0.4000\n",
      "Epoch 3/60\n",
      "984/984 [==============================] - 831s 845ms/step - loss: 1.1034 - rpn_class_loss: 0.0074 - rpn_bbox_loss: 0.3096 - mrcnn_class_loss: 0.0505 - mrcnn_bbox_loss: 0.3331 - mrcnn_mask_loss: 0.4027 - val_loss: 1.2764 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.3769 - val_mrcnn_class_loss: 0.0709 - val_mrcnn_bbox_loss: 0.3935 - val_mrcnn_mask_loss: 0.4271\n",
      "Epoch 4/60\n",
      "984/984 [==============================] - 832s 845ms/step - loss: 1.0926 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.2883 - mrcnn_class_loss: 0.0669 - mrcnn_bbox_loss: 0.3255 - mrcnn_mask_loss: 0.4059 - val_loss: 1.2093 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.3551 - val_mrcnn_class_loss: 0.0913 - val_mrcnn_bbox_loss: 0.3549 - val_mrcnn_mask_loss: 0.4022\n",
      "Epoch 5/60\n",
      "984/984 [==============================] - 828s 842ms/step - loss: 1.0593 - rpn_class_loss: 0.0053 - rpn_bbox_loss: 0.2648 - mrcnn_class_loss: 0.0840 - mrcnn_bbox_loss: 0.3082 - mrcnn_mask_loss: 0.3969 - val_loss: 1.1426 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.2927 - val_mrcnn_class_loss: 0.1044 - val_mrcnn_bbox_loss: 0.3412 - val_mrcnn_mask_loss: 0.3999\n",
      "Epoch 6/60\n",
      "984/984 [==============================] - 812s 825ms/step - loss: 1.0207 - rpn_class_loss: 0.0045 - rpn_bbox_loss: 0.2313 - mrcnn_class_loss: 0.0923 - mrcnn_bbox_loss: 0.2954 - mrcnn_mask_loss: 0.3971 - val_loss: 1.1320 - val_rpn_class_loss: 0.0040 - val_rpn_bbox_loss: 0.2685 - val_mrcnn_class_loss: 0.1074 - val_mrcnn_bbox_loss: 0.3529 - val_mrcnn_mask_loss: 0.3992\n",
      "Epoch 7/60\n",
      "984/984 [==============================] - 806s 819ms/step - loss: 1.0042 - rpn_class_loss: 0.0041 - rpn_bbox_loss: 0.2107 - mrcnn_class_loss: 0.1073 - mrcnn_bbox_loss: 0.2888 - mrcnn_mask_loss: 0.3934 - val_loss: 1.1143 - val_rpn_class_loss: 0.0037 - val_rpn_bbox_loss: 0.2721 - val_mrcnn_class_loss: 0.1076 - val_mrcnn_bbox_loss: 0.3335 - val_mrcnn_mask_loss: 0.3975\n",
      "Epoch 8/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.9500 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.1828 - mrcnn_class_loss: 0.1118 - mrcnn_bbox_loss: 0.2655 - mrcnn_mask_loss: 0.3863 - val_loss: 1.1505 - val_rpn_class_loss: 0.0034 - val_rpn_bbox_loss: 0.2879 - val_mrcnn_class_loss: 0.1346 - val_mrcnn_bbox_loss: 0.3286 - val_mrcnn_mask_loss: 0.3961\n",
      "Epoch 9/60\n",
      "984/984 [==============================] - 806s 819ms/step - loss: 0.8890 - rpn_class_loss: 0.0034 - rpn_bbox_loss: 0.1568 - mrcnn_class_loss: 0.1153 - mrcnn_bbox_loss: 0.2391 - mrcnn_mask_loss: 0.3744 - val_loss: 1.1510 - val_rpn_class_loss: 0.0034 - val_rpn_bbox_loss: 0.2971 - val_mrcnn_class_loss: 0.1277 - val_mrcnn_bbox_loss: 0.3337 - val_mrcnn_mask_loss: 0.3891\n",
      "Epoch 10/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.8447 - rpn_class_loss: 0.0031 - rpn_bbox_loss: 0.1333 - mrcnn_class_loss: 0.1213 - mrcnn_bbox_loss: 0.2196 - mrcnn_mask_loss: 0.3675 - val_loss: 1.1793 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.3482 - val_mrcnn_class_loss: 0.1364 - val_mrcnn_bbox_loss: 0.3178 - val_mrcnn_mask_loss: 0.3736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/60\n",
      "984/984 [==============================] - 809s 823ms/step - loss: 0.8031 - rpn_class_loss: 0.0030 - rpn_bbox_loss: 0.1218 - mrcnn_class_loss: 0.1195 - mrcnn_bbox_loss: 0.2000 - mrcnn_mask_loss: 0.3588 - val_loss: 1.1603 - val_rpn_class_loss: 0.0030 - val_rpn_bbox_loss: 0.2916 - val_mrcnn_class_loss: 0.1418 - val_mrcnn_bbox_loss: 0.3378 - val_mrcnn_mask_loss: 0.3862\n",
      "Epoch 12/60\n",
      "984/984 [==============================] - 810s 824ms/step - loss: 0.7393 - rpn_class_loss: 0.0028 - rpn_bbox_loss: 0.0982 - mrcnn_class_loss: 0.1174 - mrcnn_bbox_loss: 0.1757 - mrcnn_mask_loss: 0.3452 - val_loss: 1.1646 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3261 - val_mrcnn_class_loss: 0.1456 - val_mrcnn_bbox_loss: 0.3173 - val_mrcnn_mask_loss: 0.3727\n",
      "Epoch 13/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.7080 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0878 - mrcnn_class_loss: 0.1193 - mrcnn_bbox_loss: 0.1592 - mrcnn_mask_loss: 0.3391 - val_loss: 1.2166 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3544 - val_mrcnn_class_loss: 0.1332 - val_mrcnn_bbox_loss: 0.3241 - val_mrcnn_mask_loss: 0.4019\n",
      "Epoch 14/60\n",
      "984/984 [==============================] - 806s 819ms/step - loss: 0.6501 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0756 - mrcnn_class_loss: 0.1105 - mrcnn_bbox_loss: 0.1376 - mrcnn_mask_loss: 0.3239 - val_loss: 1.2116 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3111 - val_mrcnn_class_loss: 0.1686 - val_mrcnn_bbox_loss: 0.3304 - val_mrcnn_mask_loss: 0.3988\n",
      "Epoch 15/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.6105 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0675 - mrcnn_class_loss: 0.1059 - mrcnn_bbox_loss: 0.1228 - mrcnn_mask_loss: 0.3119 - val_loss: 1.2521 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3103 - val_mrcnn_class_loss: 0.1753 - val_mrcnn_bbox_loss: 0.3431 - val_mrcnn_mask_loss: 0.4208\n",
      "Epoch 16/60\n",
      "984/984 [==============================] - 809s 822ms/step - loss: 0.5743 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0611 - mrcnn_class_loss: 0.1007 - mrcnn_bbox_loss: 0.1086 - mrcnn_mask_loss: 0.3017 - val_loss: 1.2947 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3691 - val_mrcnn_class_loss: 0.1913 - val_mrcnn_bbox_loss: 0.3298 - val_mrcnn_mask_loss: 0.4019\n",
      "Epoch 17/60\n",
      "984/984 [==============================] - 806s 819ms/step - loss: 0.5446 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0567 - mrcnn_class_loss: 0.0992 - mrcnn_bbox_loss: 0.0975 - mrcnn_mask_loss: 0.2891 - val_loss: 1.2743 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3302 - val_mrcnn_class_loss: 0.2148 - val_mrcnn_bbox_loss: 0.3232 - val_mrcnn_mask_loss: 0.4034\n",
      "Epoch 18/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.5070 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0486 - mrcnn_class_loss: 0.0914 - mrcnn_bbox_loss: 0.0888 - mrcnn_mask_loss: 0.2763 - val_loss: 1.2875 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.3443 - val_mrcnn_class_loss: 0.1796 - val_mrcnn_bbox_loss: 0.3325 - val_mrcnn_mask_loss: 0.4287\n",
      "Epoch 19/60\n",
      "984/984 [==============================] - 808s 821ms/step - loss: 0.4771 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0477 - mrcnn_class_loss: 0.0840 - mrcnn_bbox_loss: 0.0788 - mrcnn_mask_loss: 0.2647 - val_loss: 1.3066 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.3568 - val_mrcnn_class_loss: 0.2072 - val_mrcnn_bbox_loss: 0.3274 - val_mrcnn_mask_loss: 0.4127\n",
      "Epoch 20/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.4458 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0438 - mrcnn_class_loss: 0.0731 - mrcnn_bbox_loss: 0.0734 - mrcnn_mask_loss: 0.2537 - val_loss: 1.3940 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3362 - val_mrcnn_class_loss: 0.2764 - val_mrcnn_bbox_loss: 0.3375 - val_mrcnn_mask_loss: 0.4415\n",
      "Epoch 21/60\n",
      "984/984 [==============================] - 808s 821ms/step - loss: 0.4232 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0432 - mrcnn_class_loss: 0.0679 - mrcnn_bbox_loss: 0.0675 - mrcnn_mask_loss: 0.2429 - val_loss: 1.5436 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.3208 - val_mrcnn_class_loss: 0.3667 - val_mrcnn_bbox_loss: 0.3356 - val_mrcnn_mask_loss: 0.5178\n",
      "Epoch 22/60\n",
      "984/984 [==============================] - 806s 819ms/step - loss: 0.4067 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0408 - mrcnn_class_loss: 0.0635 - mrcnn_bbox_loss: 0.0637 - mrcnn_mask_loss: 0.2370 - val_loss: 1.5220 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.3234 - val_mrcnn_class_loss: 0.3441 - val_mrcnn_bbox_loss: 0.3482 - val_mrcnn_mask_loss: 0.5039\n",
      "Epoch 23/60\n",
      "984/984 [==============================] - 807s 821ms/step - loss: 0.3878 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0384 - mrcnn_class_loss: 0.0599 - mrcnn_bbox_loss: 0.0587 - mrcnn_mask_loss: 0.2293 - val_loss: 1.6273 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3084 - val_mrcnn_class_loss: 0.3711 - val_mrcnn_bbox_loss: 0.3726 - val_mrcnn_mask_loss: 0.5728\n",
      "Epoch 24/60\n",
      "984/984 [==============================] - 809s 822ms/step - loss: 0.3664 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0375 - mrcnn_class_loss: 0.0517 - mrcnn_bbox_loss: 0.0542 - mrcnn_mask_loss: 0.2215 - val_loss: 1.6051 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.3248 - val_mrcnn_class_loss: 0.4419 - val_mrcnn_bbox_loss: 0.3369 - val_mrcnn_mask_loss: 0.4992\n",
      "Epoch 25/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.3595 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0363 - mrcnn_class_loss: 0.0476 - mrcnn_bbox_loss: 0.0544 - mrcnn_mask_loss: 0.2198 - val_loss: 1.6016 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3021 - val_mrcnn_class_loss: 0.3860 - val_mrcnn_bbox_loss: 0.3481 - val_mrcnn_mask_loss: 0.5628\n",
      "Epoch 26/60\n",
      "984/984 [==============================] - 808s 821ms/step - loss: 0.3320 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0327 - mrcnn_class_loss: 0.0439 - mrcnn_bbox_loss: 0.0471 - mrcnn_mask_loss: 0.2069 - val_loss: 1.8157 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3286 - val_mrcnn_class_loss: 0.4751 - val_mrcnn_bbox_loss: 0.3647 - val_mrcnn_mask_loss: 0.6447\n",
      "Epoch 27/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.3345 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0339 - mrcnn_class_loss: 0.0468 - mrcnn_bbox_loss: 0.0467 - mrcnn_mask_loss: 0.2058 - val_loss: 1.6603 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3477 - val_mrcnn_class_loss: 0.4258 - val_mrcnn_bbox_loss: 0.3571 - val_mrcnn_mask_loss: 0.5269\n",
      "Epoch 28/60\n",
      "984/984 [==============================] - 806s 819ms/step - loss: 0.3191 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0320 - mrcnn_class_loss: 0.0404 - mrcnn_bbox_loss: 0.0446 - mrcnn_mask_loss: 0.2008 - val_loss: 1.7718 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.3196 - val_mrcnn_class_loss: 0.4859 - val_mrcnn_bbox_loss: 0.3526 - val_mrcnn_mask_loss: 0.6113\n",
      "Epoch 29/60\n",
      "984/984 [==============================] - 806s 820ms/step - loss: 0.3065 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0308 - mrcnn_class_loss: 0.0396 - mrcnn_bbox_loss: 0.0418 - mrcnn_mask_loss: 0.1929 - val_loss: 1.8704 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3345 - val_mrcnn_class_loss: 0.5720 - val_mrcnn_bbox_loss: 0.3558 - val_mrcnn_mask_loss: 0.6057\n",
      "Epoch 30/60\n",
      "984/984 [==============================] - 808s 821ms/step - loss: 0.3002 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0291 - mrcnn_class_loss: 0.0392 - mrcnn_bbox_loss: 0.0411 - mrcnn_mask_loss: 0.1897 - val_loss: 1.9303 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.2947 - val_mrcnn_class_loss: 0.6553 - val_mrcnn_bbox_loss: 0.3703 - val_mrcnn_mask_loss: 0.6076\n",
      "Epoch 31/60\n",
      "984/984 [==============================] - 809s 822ms/step - loss: 0.2912 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0265 - mrcnn_class_loss: 0.0372 - mrcnn_bbox_loss: 0.0387 - mrcnn_mask_loss: 0.1876 - val_loss: 1.7451 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3556 - val_mrcnn_class_loss: 0.4482 - val_mrcnn_bbox_loss: 0.3275 - val_mrcnn_mask_loss: 0.6111\n",
      "Epoch 32/60\n",
      "984/984 [==============================] - 809s 822ms/step - loss: 0.2859 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0276 - mrcnn_class_loss: 0.0370 - mrcnn_bbox_loss: 0.0375 - mrcnn_mask_loss: 0.1826 - val_loss: 2.2875 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3078 - val_mrcnn_class_loss: 0.7573 - val_mrcnn_bbox_loss: 0.3922 - val_mrcnn_mask_loss: 0.8273\n",
      "Epoch 33/60\n",
      "984/984 [==============================] - 809s 822ms/step - loss: 0.2770 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0282 - mrcnn_class_loss: 0.0337 - mrcnn_bbox_loss: 0.0359 - mrcnn_mask_loss: 0.1780 - val_loss: 1.7694 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.3235 - val_mrcnn_class_loss: 0.5485 - val_mrcnn_bbox_loss: 0.3392 - val_mrcnn_mask_loss: 0.5559\n",
      "Epoch 34/60\n",
      "984/984 [==============================] - 806s 820ms/step - loss: 0.2749 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0267 - mrcnn_class_loss: 0.0357 - mrcnn_bbox_loss: 0.0357 - mrcnn_mask_loss: 0.1757 - val_loss: 1.7791 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3601 - val_mrcnn_class_loss: 0.5523 - val_mrcnn_bbox_loss: 0.3238 - val_mrcnn_mask_loss: 0.5404\n",
      "Epoch 35/60\n",
      "984/984 [==============================] - 808s 821ms/step - loss: 0.2644 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0258 - mrcnn_class_loss: 0.0317 - mrcnn_bbox_loss: 0.0339 - mrcnn_mask_loss: 0.1720 - val_loss: 1.7712 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3526 - val_mrcnn_class_loss: 0.5196 - val_mrcnn_bbox_loss: 0.3345 - val_mrcnn_mask_loss: 0.5619\n",
      "Epoch 36/60\n",
      "984/984 [==============================] - 810s 823ms/step - loss: 0.2597 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0249 - mrcnn_class_loss: 0.0329 - mrcnn_bbox_loss: 0.0323 - mrcnn_mask_loss: 0.1685 - val_loss: 1.8720 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3435 - val_mrcnn_class_loss: 0.5782 - val_mrcnn_bbox_loss: 0.3458 - val_mrcnn_mask_loss: 0.6017\n",
      "Epoch 37/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.2497 - rpn_class_loss: 9.8134e-04 - rpn_bbox_loss: 0.0239 - mrcnn_class_loss: 0.0302 - mrcnn_bbox_loss: 0.0313 - mrcnn_mask_loss: 0.1634 - val_loss: 1.8268 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3668 - val_mrcnn_class_loss: 0.5500 - val_mrcnn_bbox_loss: 0.3361 - val_mrcnn_mask_loss: 0.5713\n",
      "Epoch 38/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.2456 - rpn_class_loss: 9.4850e-04 - rpn_bbox_loss: 0.0221 - mrcnn_class_loss: 0.0310 - mrcnn_bbox_loss: 0.0303 - mrcnn_mask_loss: 0.1612 - val_loss: 2.0026 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.3159 - val_mrcnn_class_loss: 0.6434 - val_mrcnn_bbox_loss: 0.3642 - val_mrcnn_mask_loss: 0.6765\n",
      "Epoch 39/60\n",
      "984/984 [==============================] - 806s 819ms/step - loss: 0.2413 - rpn_class_loss: 9.1755e-04 - rpn_bbox_loss: 0.0225 - mrcnn_class_loss: 0.0301 - mrcnn_bbox_loss: 0.0291 - mrcnn_mask_loss: 0.1587 - val_loss: 1.9285 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.3784 - val_mrcnn_class_loss: 0.5892 - val_mrcnn_bbox_loss: 0.3271 - val_mrcnn_mask_loss: 0.6314\n",
      "Epoch 40/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.2352 - rpn_class_loss: 8.9099e-04 - rpn_bbox_loss: 0.0226 - mrcnn_class_loss: 0.0276 - mrcnn_bbox_loss: 0.0287 - mrcnn_mask_loss: 0.1553 - val_loss: 1.9765 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.3259 - val_mrcnn_class_loss: 0.6408 - val_mrcnn_bbox_loss: 0.3505 - val_mrcnn_mask_loss: 0.6567\n",
      "Epoch 41/60\n",
      "984/984 [==============================] - 813s 826ms/step - loss: 0.2314 - rpn_class_loss: 8.6250e-04 - rpn_bbox_loss: 0.0214 - mrcnn_class_loss: 0.0271 - mrcnn_bbox_loss: 0.0281 - mrcnn_mask_loss: 0.1539 - val_loss: 1.9402 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3633 - val_mrcnn_class_loss: 0.5856 - val_mrcnn_bbox_loss: 0.3310 - val_mrcnn_mask_loss: 0.6573\n",
      "Epoch 42/60\n",
      "984/984 [==============================] - 808s 822ms/step - loss: 0.2222 - rpn_class_loss: 8.7224e-04 - rpn_bbox_loss: 0.0200 - mrcnn_class_loss: 0.0259 - mrcnn_bbox_loss: 0.0249 - mrcnn_mask_loss: 0.1505 - val_loss: 2.1382 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.3443 - val_mrcnn_class_loss: 0.7172 - val_mrcnn_bbox_loss: 0.3559 - val_mrcnn_mask_loss: 0.7182\n",
      "Epoch 43/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.2200 - rpn_class_loss: 8.5633e-04 - rpn_bbox_loss: 0.0202 - mrcnn_class_loss: 0.0265 - mrcnn_bbox_loss: 0.0256 - mrcnn_mask_loss: 0.1468 - val_loss: 1.9498 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.3337 - val_mrcnn_class_loss: 0.5846 - val_mrcnn_bbox_loss: 0.3386 - val_mrcnn_mask_loss: 0.6905\n",
      "Epoch 44/60\n",
      "984/984 [==============================] - 807s 820ms/step - loss: 0.2181 - rpn_class_loss: 8.2587e-04 - rpn_bbox_loss: 0.0194 - mrcnn_class_loss: 0.0257 - mrcnn_bbox_loss: 0.0249 - mrcnn_mask_loss: 0.1473 - val_loss: 2.2814 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3281 - val_mrcnn_class_loss: 0.7837 - val_mrcnn_bbox_loss: 0.3508 - val_mrcnn_mask_loss: 0.8163\n",
      "Epoch 45/60\n",
      "984/984 [==============================] - 808s 821ms/step - loss: 0.2151 - rpn_class_loss: 8.0644e-04 - rpn_bbox_loss: 0.0200 - mrcnn_class_loss: 0.0259 - mrcnn_bbox_loss: 0.0240 - mrcnn_mask_loss: 0.1444 - val_loss: 2.1510 - val_rpn_class_loss: 0.0031 - val_rpn_bbox_loss: 0.3818 - val_mrcnn_class_loss: 0.7465 - val_mrcnn_bbox_loss: 0.3220 - val_mrcnn_mask_loss: 0.6975\n",
      "Epoch 46/60\n",
      "984/984 [==============================] - 831s 845ms/step - loss: 0.2116 - rpn_class_loss: 8.0955e-04 - rpn_bbox_loss: 0.0186 - mrcnn_class_loss: 0.0257 - mrcnn_bbox_loss: 0.0243 - mrcnn_mask_loss: 0.1421 - val_loss: 2.1373 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.3322 - val_mrcnn_class_loss: 0.7931 - val_mrcnn_bbox_loss: 0.3364 - val_mrcnn_mask_loss: 0.6734\n",
      "Epoch 47/60\n",
      "984/984 [==============================] - 833s 846ms/step - loss: 0.2037 - rpn_class_loss: 7.5982e-04 - rpn_bbox_loss: 0.0181 - mrcnn_class_loss: 0.0239 - mrcnn_bbox_loss: 0.0223 - mrcnn_mask_loss: 0.1385 - val_loss: 2.2642 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.3647 - val_mrcnn_class_loss: 0.8260 - val_mrcnn_bbox_loss: 0.3290 - val_mrcnn_mask_loss: 0.7412\n",
      "Epoch 48/60\n",
      "984/984 [==============================] - 832s 846ms/step - loss: 0.1996 - rpn_class_loss: 7.5463e-04 - rpn_bbox_loss: 0.0179 - mrcnn_class_loss: 0.0220 - mrcnn_bbox_loss: 0.0223 - mrcnn_mask_loss: 0.1366 - val_loss: 2.3941 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3069 - val_mrcnn_class_loss: 0.7946 - val_mrcnn_bbox_loss: 0.3677 - val_mrcnn_mask_loss: 0.9220\n",
      "Epoch 49/60\n",
      "984/984 [==============================] - 832s 846ms/step - loss: 0.1989 - rpn_class_loss: 7.5175e-04 - rpn_bbox_loss: 0.0183 - mrcnn_class_loss: 0.0215 - mrcnn_bbox_loss: 0.0221 - mrcnn_mask_loss: 0.1362 - val_loss: 2.1476 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3270 - val_mrcnn_class_loss: 0.7355 - val_mrcnn_bbox_loss: 0.3558 - val_mrcnn_mask_loss: 0.7264\n",
      "Epoch 50/60\n",
      "984/984 [==============================] - 833s 847ms/step - loss: 0.1954 - rpn_class_loss: 7.1644e-04 - rpn_bbox_loss: 0.0181 - mrcnn_class_loss: 0.0216 - mrcnn_bbox_loss: 0.0210 - mrcnn_mask_loss: 0.1340 - val_loss: 2.1827 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3248 - val_mrcnn_class_loss: 0.7780 - val_mrcnn_bbox_loss: 0.3384 - val_mrcnn_mask_loss: 0.7386\n",
      "Epoch 51/60\n",
      "984/984 [==============================] - 834s 847ms/step - loss: 0.1905 - rpn_class_loss: 7.1997e-04 - rpn_bbox_loss: 0.0156 - mrcnn_class_loss: 0.0221 - mrcnn_bbox_loss: 0.0203 - mrcnn_mask_loss: 0.1319 - val_loss: 2.0567 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3654 - val_mrcnn_class_loss: 0.6412 - val_mrcnn_bbox_loss: 0.3380 - val_mrcnn_mask_loss: 0.7092\n",
      "Epoch 52/60\n",
      "984/984 [==============================] - 832s 845ms/step - loss: 0.1879 - rpn_class_loss: 6.9785e-04 - rpn_bbox_loss: 0.0160 - mrcnn_class_loss: 0.0215 - mrcnn_bbox_loss: 0.0197 - mrcnn_mask_loss: 0.1299 - val_loss: 1.8963 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3616 - val_mrcnn_class_loss: 0.5257 - val_mrcnn_bbox_loss: 0.3372 - val_mrcnn_mask_loss: 0.6691\n",
      "Epoch 53/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984/984 [==============================] - 831s 845ms/step - loss: 0.1840 - rpn_class_loss: 6.5612e-04 - rpn_bbox_loss: 0.0159 - mrcnn_class_loss: 0.0209 - mrcnn_bbox_loss: 0.0189 - mrcnn_mask_loss: 0.1277 - val_loss: 2.3100 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.3501 - val_mrcnn_class_loss: 0.8233 - val_mrcnn_bbox_loss: 0.3451 - val_mrcnn_mask_loss: 0.7882\n",
      "Epoch 54/60\n",
      "984/984 [==============================] - 832s 846ms/step - loss: 0.1850 - rpn_class_loss: 6.8979e-04 - rpn_bbox_loss: 0.0157 - mrcnn_class_loss: 0.0220 - mrcnn_bbox_loss: 0.0192 - mrcnn_mask_loss: 0.1274 - val_loss: 2.1762 - val_rpn_class_loss: 0.0034 - val_rpn_bbox_loss: 0.3517 - val_mrcnn_class_loss: 0.6564 - val_mrcnn_bbox_loss: 0.3617 - val_mrcnn_mask_loss: 0.8030\n",
      "Epoch 55/60\n",
      "984/984 [==============================] - 832s 846ms/step - loss: 0.1807 - rpn_class_loss: 6.4021e-04 - rpn_bbox_loss: 0.0145 - mrcnn_class_loss: 0.0232 - mrcnn_bbox_loss: 0.0187 - mrcnn_mask_loss: 0.1236 - val_loss: 2.1490 - val_rpn_class_loss: 0.0031 - val_rpn_bbox_loss: 0.3498 - val_mrcnn_class_loss: 0.7491 - val_mrcnn_bbox_loss: 0.3386 - val_mrcnn_mask_loss: 0.7083\n",
      "Epoch 56/60\n",
      "984/984 [==============================] - 834s 847ms/step - loss: 0.1766 - rpn_class_loss: 6.2618e-04 - rpn_bbox_loss: 0.0153 - mrcnn_class_loss: 0.0197 - mrcnn_bbox_loss: 0.0181 - mrcnn_mask_loss: 0.1228 - val_loss: 2.1536 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3463 - val_mrcnn_class_loss: 0.6739 - val_mrcnn_bbox_loss: 0.3354 - val_mrcnn_mask_loss: 0.7950\n",
      "Epoch 57/60\n",
      "984/984 [==============================] - 832s 846ms/step - loss: 0.1725 - rpn_class_loss: 6.2035e-04 - rpn_bbox_loss: 0.0147 - mrcnn_class_loss: 0.0189 - mrcnn_bbox_loss: 0.0173 - mrcnn_mask_loss: 0.1210 - val_loss: 2.4311 - val_rpn_class_loss: 0.0034 - val_rpn_bbox_loss: 0.3246 - val_mrcnn_class_loss: 0.9854 - val_mrcnn_bbox_loss: 0.3590 - val_mrcnn_mask_loss: 0.7587\n",
      "Epoch 58/60\n",
      "984/984 [==============================] - 832s 845ms/step - loss: 0.1703 - rpn_class_loss: 6.0073e-04 - rpn_bbox_loss: 0.0140 - mrcnn_class_loss: 0.0194 - mrcnn_bbox_loss: 0.0173 - mrcnn_mask_loss: 0.1189 - val_loss: 2.2301 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3406 - val_mrcnn_class_loss: 0.7917 - val_mrcnn_bbox_loss: 0.3386 - val_mrcnn_mask_loss: 0.7564\n",
      "Epoch 59/60\n",
      "984/984 [==============================] - 831s 845ms/step - loss: 0.1667 - rpn_class_loss: 5.7760e-04 - rpn_bbox_loss: 0.0139 - mrcnn_class_loss: 0.0185 - mrcnn_bbox_loss: 0.0163 - mrcnn_mask_loss: 0.1175 - val_loss: 2.3534 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.3363 - val_mrcnn_class_loss: 0.8975 - val_mrcnn_bbox_loss: 0.3410 - val_mrcnn_mask_loss: 0.7760\n",
      "Epoch 60/60\n",
      "984/984 [==============================] - 832s 846ms/step - loss: 0.1666 - rpn_class_loss: 5.7730e-04 - rpn_bbox_loss: 0.0127 - mrcnn_class_loss: 0.0194 - mrcnn_bbox_loss: 0.0165 - mrcnn_mask_loss: 0.1174 - val_loss: 2.5489 - val_rpn_class_loss: 0.0040 - val_rpn_bbox_loss: 0.3525 - val_mrcnn_class_loss: 0.8992 - val_mrcnn_bbox_loss: 0.3395 - val_mrcnn_mask_loss: 0.9537\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "# Use configuation from mammo.py, but override\n",
    "# image resizing so we see the real sizes here\n",
    "class NoResizeConfig(mammo.MammoConfig):\n",
    "#     IMAGE_RESIZE_MODE = \"none\"\n",
    "#     USE_MINI_MASK = False\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 512\n",
    "    \n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 1000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "    \n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "    \n",
    "config = NoResizeConfig()\n",
    "config.display()\n",
    "\n",
    "MODEL_DIR = 'checkpoints'\n",
    "\n",
    "# Create model\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,                          \n",
    "                          model_dir=MODEL_DIR)\n",
    "# Select weights file to load\n",
    "weights_path = model.get_imagenet_weights()\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "model.train(dataset_train, dataset_val, config.LEARNING_RATE, epochs=60, layers='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training #1 \n",
    "### With proper bounding box and 40 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [54.78 54.78 54.78]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           mammo\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        3000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (16, 32, 64, 128, 256)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    512\n",
      "STEPS_PER_EPOCH                984\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               245\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  C:\\Users\\Chevy\\AppData\\Local\\Temp\\.keras\\models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: checkpoints\\mammo20180715T0134\\mask_rcnn_mammo_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chevy\\Anaconda3\\envs\\nnets\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/40\n",
      "984/984 [==============================] - 1247s 1s/step - loss: 1.2758 - rpn_class_loss: 0.0329 - rpn_bbox_loss: 0.4854 - mrcnn_class_loss: 0.0232 - mrcnn_bbox_loss: 0.3555 - mrcnn_mask_loss: 0.3788 - val_loss: 1.3156 - val_rpn_class_loss: 0.0097 - val_rpn_bbox_loss: 0.3549 - val_mrcnn_class_loss: 0.0312 - val_mrcnn_bbox_loss: 0.4126 - val_mrcnn_mask_loss: 0.5071\n",
      "Epoch 2/40\n",
      "984/984 [==============================] - 1256s 1s/step - loss: 1.1666 - rpn_class_loss: 0.0099 - rpn_bbox_loss: 0.3424 - mrcnn_class_loss: 0.0296 - mrcnn_bbox_loss: 0.3471 - mrcnn_mask_loss: 0.4376 - val_loss: 1.1942 - val_rpn_class_loss: 0.0067 - val_rpn_bbox_loss: 0.3149 - val_mrcnn_class_loss: 0.0339 - val_mrcnn_bbox_loss: 0.3668 - val_mrcnn_mask_loss: 0.4718\n",
      "Epoch 3/40\n",
      "984/984 [==============================] - 1325s 1s/step - loss: 1.1267 - rpn_class_loss: 0.0069 - rpn_bbox_loss: 0.3054 - mrcnn_class_loss: 0.0365 - mrcnn_bbox_loss: 0.3474 - mrcnn_mask_loss: 0.4304 - val_loss: 1.2822 - val_rpn_class_loss: 0.0064 - val_rpn_bbox_loss: 0.2952 - val_mrcnn_class_loss: 0.0387 - val_mrcnn_bbox_loss: 0.3722 - val_mrcnn_mask_loss: 0.5697\n",
      "Epoch 4/40\n",
      "984/984 [==============================] - 1329s 1s/step - loss: 1.0508 - rpn_class_loss: 0.0058 - rpn_bbox_loss: 0.2713 - mrcnn_class_loss: 0.0375 - mrcnn_bbox_loss: 0.3238 - mrcnn_mask_loss: 0.4123 - val_loss: 1.0860 - val_rpn_class_loss: 0.0055 - val_rpn_bbox_loss: 0.2770 - val_mrcnn_class_loss: 0.0447 - val_mrcnn_bbox_loss: 0.3344 - val_mrcnn_mask_loss: 0.4244\n",
      "Epoch 5/40\n",
      "984/984 [==============================] - 1333s 1s/step - loss: 0.9920 - rpn_class_loss: 0.0047 - rpn_bbox_loss: 0.2510 - mrcnn_class_loss: 0.0382 - mrcnn_bbox_loss: 0.2996 - mrcnn_mask_loss: 0.3985 - val_loss: 1.0627 - val_rpn_class_loss: 0.0044 - val_rpn_bbox_loss: 0.2806 - val_mrcnn_class_loss: 0.0357 - val_mrcnn_bbox_loss: 0.3439 - val_mrcnn_mask_loss: 0.3980\n",
      "Epoch 6/40\n",
      "984/984 [==============================] - 1350s 1s/step - loss: 0.9459 - rpn_class_loss: 0.0041 - rpn_bbox_loss: 0.2186 - mrcnn_class_loss: 0.0395 - mrcnn_bbox_loss: 0.2898 - mrcnn_mask_loss: 0.3940 - val_loss: 1.1489 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.3144 - val_mrcnn_class_loss: 0.0454 - val_mrcnn_bbox_loss: 0.3464 - val_mrcnn_mask_loss: 0.4386\n",
      "Epoch 7/40\n",
      "984/984 [==============================] - 1363s 1s/step - loss: 0.8883 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.1994 - mrcnn_class_loss: 0.0390 - mrcnn_bbox_loss: 0.2690 - mrcnn_mask_loss: 0.3771 - val_loss: 1.0320 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.3001 - val_mrcnn_class_loss: 0.0371 - val_mrcnn_bbox_loss: 0.3158 - val_mrcnn_mask_loss: 0.3758\n",
      "Epoch 8/40\n",
      "984/984 [==============================] - 1336s 1s/step - loss: 0.8423 - rpn_class_loss: 0.0034 - rpn_bbox_loss: 0.1737 - mrcnn_class_loss: 0.0346 - mrcnn_bbox_loss: 0.2567 - mrcnn_mask_loss: 0.3739 - val_loss: 1.0199 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.2906 - val_mrcnn_class_loss: 0.0404 - val_mrcnn_bbox_loss: 0.3056 - val_mrcnn_mask_loss: 0.3801\n",
      "Epoch 9/40\n",
      "984/984 [==============================] - 1349s 1s/step - loss: 0.7757 - rpn_class_loss: 0.0031 - rpn_bbox_loss: 0.1488 - mrcnn_class_loss: 0.0322 - mrcnn_bbox_loss: 0.2326 - mrcnn_mask_loss: 0.3590 - val_loss: 1.0122 - val_rpn_class_loss: 0.0034 - val_rpn_bbox_loss: 0.3220 - val_mrcnn_class_loss: 0.0315 - val_mrcnn_bbox_loss: 0.3002 - val_mrcnn_mask_loss: 0.3552\n",
      "Epoch 10/40\n",
      "984/984 [==============================] - 1354s 1s/step - loss: 0.7345 - rpn_class_loss: 0.0029 - rpn_bbox_loss: 0.1319 - mrcnn_class_loss: 0.0319 - mrcnn_bbox_loss: 0.2168 - mrcnn_mask_loss: 0.3510 - val_loss: 1.1505 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3392 - val_mrcnn_class_loss: 0.0454 - val_mrcnn_bbox_loss: 0.3243 - val_mrcnn_mask_loss: 0.4387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "984/984 [==============================] - 1350s 1s/step - loss: 0.6850 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.1114 - mrcnn_class_loss: 0.0289 - mrcnn_bbox_loss: 0.1996 - mrcnn_mask_loss: 0.3425 - val_loss: 1.1400 - val_rpn_class_loss: 0.0030 - val_rpn_bbox_loss: 0.3213 - val_mrcnn_class_loss: 0.0514 - val_mrcnn_bbox_loss: 0.3276 - val_mrcnn_mask_loss: 0.4367\n",
      "Epoch 12/40\n",
      "984/984 [==============================] - 1358s 1s/step - loss: 0.6486 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0993 - mrcnn_class_loss: 0.0269 - mrcnn_bbox_loss: 0.1840 - mrcnn_mask_loss: 0.3360 - val_loss: 1.0837 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.4048 - val_mrcnn_class_loss: 0.0297 - val_mrcnn_bbox_loss: 0.2958 - val_mrcnn_mask_loss: 0.3509\n",
      "Epoch 13/40\n",
      "984/984 [==============================] - 1358s 1s/step - loss: 0.5991 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0865 - mrcnn_class_loss: 0.0244 - mrcnn_bbox_loss: 0.1646 - mrcnn_mask_loss: 0.3212 - val_loss: 1.0945 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3470 - val_mrcnn_class_loss: 0.0390 - val_mrcnn_bbox_loss: 0.3187 - val_mrcnn_mask_loss: 0.3872\n",
      "Epoch 14/40\n",
      "984/984 [==============================] - 1348s 1s/step - loss: 0.5562 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0784 - mrcnn_class_loss: 0.0216 - mrcnn_bbox_loss: 0.1465 - mrcnn_mask_loss: 0.3076 - val_loss: 1.1062 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.4000 - val_mrcnn_class_loss: 0.0305 - val_mrcnn_bbox_loss: 0.2994 - val_mrcnn_mask_loss: 0.3736\n",
      "Epoch 15/40\n",
      "984/984 [==============================] - 1355s 1s/step - loss: 0.5243 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0691 - mrcnn_class_loss: 0.0191 - mrcnn_bbox_loss: 0.1323 - mrcnn_mask_loss: 0.3017 - val_loss: 1.1029 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.3437 - val_mrcnn_class_loss: 0.0404 - val_mrcnn_bbox_loss: 0.3149 - val_mrcnn_mask_loss: 0.4013\n",
      "Epoch 16/40\n",
      "984/984 [==============================] - 1358s 1s/step - loss: 0.4952 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0646 - mrcnn_class_loss: 0.0195 - mrcnn_bbox_loss: 0.1200 - mrcnn_mask_loss: 0.2893 - val_loss: 1.0952 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.3371 - val_mrcnn_class_loss: 0.0433 - val_mrcnn_bbox_loss: 0.3097 - val_mrcnn_mask_loss: 0.4025\n",
      "Epoch 17/40\n",
      "984/984 [==============================] - 1383s 1s/step - loss: 0.4685 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0556 - mrcnn_class_loss: 0.0179 - mrcnn_bbox_loss: 0.1090 - mrcnn_mask_loss: 0.2842 - val_loss: 1.1258 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3097 - val_mrcnn_class_loss: 0.0481 - val_mrcnn_bbox_loss: 0.3355 - val_mrcnn_mask_loss: 0.4300\n",
      "Epoch 18/40\n",
      "984/984 [==============================] - 1378s 1s/step - loss: 0.4435 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0559 - mrcnn_class_loss: 0.0165 - mrcnn_bbox_loss: 0.0987 - mrcnn_mask_loss: 0.2706 - val_loss: 1.1656 - val_rpn_class_loss: 0.0022 - val_rpn_bbox_loss: 0.3152 - val_mrcnn_class_loss: 0.0478 - val_mrcnn_bbox_loss: 0.3212 - val_mrcnn_mask_loss: 0.4791\n",
      "Epoch 19/40\n",
      "984/984 [==============================] - 1366s 1s/step - loss: 0.4172 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0495 - mrcnn_class_loss: 0.0147 - mrcnn_bbox_loss: 0.0898 - mrcnn_mask_loss: 0.2616 - val_loss: 1.2217 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3666 - val_mrcnn_class_loss: 0.0680 - val_mrcnn_bbox_loss: 0.3213 - val_mrcnn_mask_loss: 0.4633\n",
      "Epoch 20/40\n",
      "984/984 [==============================] - 1372s 1s/step - loss: 0.3979 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0473 - mrcnn_class_loss: 0.0142 - mrcnn_bbox_loss: 0.0820 - mrcnn_mask_loss: 0.2528 - val_loss: 1.1366 - val_rpn_class_loss: 0.0022 - val_rpn_bbox_loss: 0.3515 - val_mrcnn_class_loss: 0.0314 - val_mrcnn_bbox_loss: 0.3192 - val_mrcnn_mask_loss: 0.4323\n",
      "Epoch 21/40\n",
      "984/984 [==============================] - 1365s 1s/step - loss: 0.3799 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0436 - mrcnn_class_loss: 0.0133 - mrcnn_bbox_loss: 0.0767 - mrcnn_mask_loss: 0.2448 - val_loss: 1.2373 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3515 - val_mrcnn_class_loss: 0.0702 - val_mrcnn_bbox_loss: 0.3316 - val_mrcnn_mask_loss: 0.4815\n",
      "Epoch 22/40\n",
      "984/984 [==============================] - 1361s 1s/step - loss: 0.3653 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0427 - mrcnn_class_loss: 0.0132 - mrcnn_bbox_loss: 0.0708 - mrcnn_mask_loss: 0.2371 - val_loss: 1.2822 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3506 - val_mrcnn_class_loss: 0.0599 - val_mrcnn_bbox_loss: 0.3312 - val_mrcnn_mask_loss: 0.5379\n",
      "Epoch 23/40\n",
      "984/984 [==============================] - 1372s 1s/step - loss: 0.3458 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0410 - mrcnn_class_loss: 0.0112 - mrcnn_bbox_loss: 0.0646 - mrcnn_mask_loss: 0.2277 - val_loss: 1.2420 - val_rpn_class_loss: 0.0022 - val_rpn_bbox_loss: 0.3338 - val_mrcnn_class_loss: 0.0654 - val_mrcnn_bbox_loss: 0.3304 - val_mrcnn_mask_loss: 0.5102\n",
      "Epoch 24/40\n",
      "984/984 [==============================] - 1365s 1s/step - loss: 0.3363 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0383 - mrcnn_class_loss: 0.0105 - mrcnn_bbox_loss: 0.0619 - mrcnn_mask_loss: 0.2242 - val_loss: 1.2035 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.3587 - val_mrcnn_class_loss: 0.0482 - val_mrcnn_bbox_loss: 0.3250 - val_mrcnn_mask_loss: 0.4693\n",
      "Epoch 25/40\n",
      "984/984 [==============================] - 1361s 1s/step - loss: 0.3253 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0380 - mrcnn_class_loss: 0.0105 - mrcnn_bbox_loss: 0.0592 - mrcnn_mask_loss: 0.2163 - val_loss: 1.3661 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.3441 - val_mrcnn_class_loss: 0.0838 - val_mrcnn_bbox_loss: 0.3426 - val_mrcnn_mask_loss: 0.5933\n",
      "Epoch 26/40\n",
      "984/984 [==============================] - 1380s 1s/step - loss: 0.3193 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0373 - mrcnn_class_loss: 0.0101 - mrcnn_bbox_loss: 0.0549 - mrcnn_mask_loss: 0.2157 - val_loss: 1.2675 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.3597 - val_mrcnn_class_loss: 0.0677 - val_mrcnn_bbox_loss: 0.3228 - val_mrcnn_mask_loss: 0.5149\n",
      "Epoch 27/40\n",
      "984/984 [==============================] - 1367s 1s/step - loss: 0.3040 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0334 - mrcnn_class_loss: 0.0087 - mrcnn_bbox_loss: 0.0532 - mrcnn_mask_loss: 0.2074 - val_loss: 1.4462 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3528 - val_mrcnn_class_loss: 0.1145 - val_mrcnn_bbox_loss: 0.3427 - val_mrcnn_mask_loss: 0.6334\n",
      "Epoch 28/40\n",
      "984/984 [==============================] - 1383s 1s/step - loss: 0.2986 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0347 - mrcnn_class_loss: 0.0084 - mrcnn_bbox_loss: 0.0500 - mrcnn_mask_loss: 0.2043 - val_loss: 1.4029 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.3579 - val_mrcnn_class_loss: 0.0787 - val_mrcnn_bbox_loss: 0.3451 - val_mrcnn_mask_loss: 0.6189\n",
      "Epoch 29/40\n",
      "984/984 [==============================] - 1365s 1s/step - loss: 0.2877 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0313 - mrcnn_class_loss: 0.0077 - mrcnn_bbox_loss: 0.0465 - mrcnn_mask_loss: 0.2011 - val_loss: 1.4366 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3446 - val_mrcnn_class_loss: 0.0843 - val_mrcnn_bbox_loss: 0.3433 - val_mrcnn_mask_loss: 0.6619\n",
      "Epoch 30/40\n",
      "984/984 [==============================] - 1357s 1s/step - loss: 0.2864 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0322 - mrcnn_class_loss: 0.0086 - mrcnn_bbox_loss: 0.0462 - mrcnn_mask_loss: 0.1983 - val_loss: 1.3484 - val_rpn_class_loss: 0.0022 - val_rpn_bbox_loss: 0.3605 - val_mrcnn_class_loss: 0.0859 - val_mrcnn_bbox_loss: 0.3250 - val_mrcnn_mask_loss: 0.5749\n",
      "Epoch 31/40\n",
      "984/984 [==============================] - 1357s 1s/step - loss: 0.2690 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0301 - mrcnn_class_loss: 0.0066 - mrcnn_bbox_loss: 0.0425 - mrcnn_mask_loss: 0.1887 - val_loss: 1.4535 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.3465 - val_mrcnn_class_loss: 0.1127 - val_mrcnn_bbox_loss: 0.3281 - val_mrcnn_mask_loss: 0.6633\n",
      "Epoch 32/40\n",
      "984/984 [==============================] - 1357s 1s/step - loss: 0.2632 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0280 - mrcnn_class_loss: 0.0074 - mrcnn_bbox_loss: 0.0419 - mrcnn_mask_loss: 0.1848 - val_loss: 1.3654 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.3367 - val_mrcnn_class_loss: 0.1015 - val_mrcnn_bbox_loss: 0.3281 - val_mrcnn_mask_loss: 0.5968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40\n",
      "984/984 [==============================] - 1354s 1s/step - loss: 0.2596 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0281 - mrcnn_class_loss: 0.0066 - mrcnn_bbox_loss: 0.0409 - mrcnn_mask_loss: 0.1829 - val_loss: 1.3726 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.3322 - val_mrcnn_class_loss: 0.0812 - val_mrcnn_bbox_loss: 0.3456 - val_mrcnn_mask_loss: 0.6113\n",
      "Epoch 34/40\n",
      "984/984 [==============================] - 1361s 1s/step - loss: 0.2577 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0281 - mrcnn_class_loss: 0.0067 - mrcnn_bbox_loss: 0.0406 - mrcnn_mask_loss: 0.1811 - val_loss: 1.7583 - val_rpn_class_loss: 0.0031 - val_rpn_bbox_loss: 0.3568 - val_mrcnn_class_loss: 0.1285 - val_mrcnn_bbox_loss: 0.3535 - val_mrcnn_mask_loss: 0.9164\n",
      "Epoch 35/40\n",
      "984/984 [==============================] - 1354s 1s/step - loss: 0.2454 - rpn_class_loss: 9.7563e-04 - rpn_bbox_loss: 0.0250 - mrcnn_class_loss: 0.0055 - mrcnn_bbox_loss: 0.0370 - mrcnn_mask_loss: 0.1769 - val_loss: 1.5053 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.4061 - val_mrcnn_class_loss: 0.1028 - val_mrcnn_bbox_loss: 0.3237 - val_mrcnn_mask_loss: 0.6703\n",
      "Epoch 36/40\n",
      "984/984 [==============================] - 1364s 1s/step - loss: 0.2385 - rpn_class_loss: 9.4172e-04 - rpn_bbox_loss: 0.0248 - mrcnn_class_loss: 0.0057 - mrcnn_bbox_loss: 0.0362 - mrcnn_mask_loss: 0.1709 - val_loss: 1.3949 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.3515 - val_mrcnn_class_loss: 0.0802 - val_mrcnn_bbox_loss: 0.3405 - val_mrcnn_mask_loss: 0.6201\n",
      "Epoch 37/40\n",
      "984/984 [==============================] - 1375s 1s/step - loss: 0.2344 - rpn_class_loss: 8.6202e-04 - rpn_bbox_loss: 0.0252 - mrcnn_class_loss: 0.0052 - mrcnn_bbox_loss: 0.0334 - mrcnn_mask_loss: 0.1698 - val_loss: 1.4195 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.3617 - val_mrcnn_class_loss: 0.1080 - val_mrcnn_bbox_loss: 0.3270 - val_mrcnn_mask_loss: 0.6202\n",
      "Epoch 38/40\n",
      "984/984 [==============================] - 1356s 1s/step - loss: 0.2317 - rpn_class_loss: 9.1858e-04 - rpn_bbox_loss: 0.0240 - mrcnn_class_loss: 0.0058 - mrcnn_bbox_loss: 0.0344 - mrcnn_mask_loss: 0.1666 - val_loss: 1.6360 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.3567 - val_mrcnn_class_loss: 0.1463 - val_mrcnn_bbox_loss: 0.3358 - val_mrcnn_mask_loss: 0.7943\n",
      "Epoch 39/40\n",
      "984/984 [==============================] - 1357s 1s/step - loss: 0.2229 - rpn_class_loss: 8.6681e-04 - rpn_bbox_loss: 0.0224 - mrcnn_class_loss: 0.0044 - mrcnn_bbox_loss: 0.0319 - mrcnn_mask_loss: 0.1633 - val_loss: 1.4857 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.3443 - val_mrcnn_class_loss: 0.1118 - val_mrcnn_bbox_loss: 0.3254 - val_mrcnn_mask_loss: 0.7014\n",
      "Epoch 40/40\n",
      "984/984 [==============================] - 1348s 1s/step - loss: 0.2212 - rpn_class_loss: 8.5379e-04 - rpn_bbox_loss: 0.0231 - mrcnn_class_loss: 0.0048 - mrcnn_bbox_loss: 0.0312 - mrcnn_mask_loss: 0.1612 - val_loss: 1.4489 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.3634 - val_mrcnn_class_loss: 0.1227 - val_mrcnn_bbox_loss: 0.3127 - val_mrcnn_mask_loss: 0.6474\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "# Use configuation from mammo.py, but override\n",
    "# image resizing so we see the real sizes here\n",
    "class NoResizeConfig(mammo.MammoConfig):\n",
    "#     IMAGE_RESIZE_MODE = \"none\"\n",
    "#     USE_MINI_MASK = False\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 512\n",
    "    \n",
    "config = NoResizeConfig()\n",
    "config.display()\n",
    "\n",
    "MODEL_DIR = 'checkpoints'\n",
    "\n",
    "# Create model\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,                          \n",
    "                          model_dir=MODEL_DIR)\n",
    "# Select weights file to load\n",
    "weights_path = model.get_imagenet_weights()\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "model.train(dataset_train, dataset_val, config.LEARNING_RATE, epochs=40, layers='all')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
